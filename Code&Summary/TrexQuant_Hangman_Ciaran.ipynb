{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "338b6984-a328-4d06-9716-def0b33f7cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import random\n",
    "import string\n",
    "import secrets\n",
    "import time\n",
    "import re\n",
    "import collections\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from urllib.parse import parse_qs, urlencode, urlparse\n",
    "except ImportError:\n",
    "    from urlparse import parse_qs, urlparse\n",
    "    from urllib import urlencode\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb218a11-5984-45ea-ac92-741133032d37",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c412f213-08f6-41ee-8f8e-30ba3b8ac2ba",
   "metadata": {},
   "source": [
    "**Sources for strategy:**\n",
    "\n",
    "- [Source 1](http://www.datagenetics.com/blog/april12012/index.html#google_vignette)\n",
    "\n",
    "http://www.datagenetics.com/blog/april12012/index.html#google_vignette \n",
    "\n",
    "- [Source 2](http://www.sharkfeeder.com/hangman/)\n",
    "  \n",
    "http://www.sharkfeeder.com/hangman/ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e40be08-6b14-46fd-93fc-50866f12a9c5",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118ad856-af44-4b03-9c71-ea63bc4c97fb",
   "metadata": {},
   "source": [
    "**Findings**\n",
    "\n",
    "When designing a Hangman solver, it is not enough to rely on raw letter frequencies from English text, since these are biased by common short words (e.g. the, and, of). Instead, probabilities should be based on dictionary word coverage—how often a letter appears in words of a given length. This shifts the priority toward vowels like E, I, A but also highlights consonants such as S (especially in 5-letter words). The optimal first guess depends strongly on word length: for example, S is best in 5-letter words, E dominates for 6–12 letters, and I becomes strongest for very long words. After each guess, conditional probability is key: the candidate word set must be filtered by hits and misses, and letter rankings recalculated dynamically.\n",
    "\n",
    "Algorithmic approaches confirm this. A recursive elimination method that repeatedly filters the dictionary by current patterns and recalculates letter frequencies can achieve near-perfect win rates, especially for words of length ≥6. In practice, optimal strategies often start with E, I, or A, but high-value consonants (S, R, T, N, L) quickly come into play. Thus, the coding solution should combine (1) a length-aware initial guess strategy and (2) a dynamic, pattern-driven update step after each guess. This ensures efficient narrowing of the wordlist and maximises the probability of solving within the allowed misses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8383b36-cc50-4739-991a-c4999610d944",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ab046d-71f8-4476-b1ee-0aad0c7ad127",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4a7a03-b00a-49f6-8d1f-cdd49f6a207b",
   "metadata": {},
   "source": [
    "**Initial Ideas:**\n",
    "\n",
    "\n",
    "1.) Entropy-based scoring (Core Decision Rule): Instead of pure frequency, calculate the expected remaining candidate set size after each possible guess, and pick the letter minimizing that. This directly maximizes information gain.\n",
    "\n",
    "2.) Regex candidate filtering with most-common-letter pick: Check log of all words which are length of the current word. Match guessed letter positions to existing words. if matches guess most common overlap. Candidate filtering by regex+Frequency.\n",
    "\n",
    "3.) Adaptive weighting across priors/entropy: Start with global letter priors, then as the mask fills in, shift weight toward positional/bigram info from remaining candidates. e.g. early vowel bias.\n",
    "\n",
    "4.) Letter frequency conditioned on length: Tie word length to letter frequency- P(letter | length). This would for example word lengths from 3-10, [0,0,0,1,0,..,0] and then for letters a-z, a frequency under each.\n",
    "\n",
    "5.) Positional frequency conditioned on length - P(letter at pos | length): how often after each letter appears at position 1, 2, 3, 4..,n for given word length n\n",
    "\n",
    "6.) Vowel/consonant ratio penalty: incorporate vowels into the scoring, not a hard cutoff. If vowels are overrepresented, just penalize them in your selection score instead of banning outright.\n",
    "\n",
    "8.) Bigram position frequency: Given letter at position - P(letter_at_pos=i+1 | letter_at_pos=i), whats the probability for each letter at the next position or previous.\n",
    "\n",
    "\n",
    "Just select one and try. ill give the output and you try another if its poor or improve the current guess functio for what you choose\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2f1dd7-d9ea-47ca-8e2a-d6c05a7683ac",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdeb132-127f-495a-aa14-ab614112fb9c",
   "metadata": {},
   "source": [
    "**Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0036e652-098f-4e18-b178-b604933790df",
   "metadata": {},
   "source": [
    " The function run_hangman_eda analyzes a large Hangman dictionary to extract statistical patterns useful for guessing strategies. It computes word length distributions, global and per-word letter frequencies, and the average vowel ratio, while also grouping words by vowel proportion. Positional statistics are gathered for each word length, including letter distributions, vowel probabilities, and entropy per slot to identify positions that are easier to guess. Additional analysis covers first and last letter frequencies, common bigrams, suffix counts (e.g., -ing, -ed, -tion), and typical consonant/vowel word shapes. A helper function allows querying the dictionary with regex-like patterns to return candidate words and positional counts. The function outputs summaries for quick inspection and returns structured results (counters, entropy maps, suffix stats, shape distributions) for downstream use in Hangman-solving models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "059c78c2-80a2-4e44-bc7c-6af7df4030c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 227300\n",
      "Word length: min=1, max=29, avg=9.35\n",
      "Most common lengths: [(9, 30906), (8, 30452), (10, 26953), (7, 25948), (11, 22786), (6, 19541), (12, 18178), (13, 12956), (5, 11274), (14, 8710)]\n",
      "Top 10 letters by global frequency: [('e', 233745), ('i', 184746), ('a', 179837), ('n', 152259), ('o', 150052), ('r', 149228), ('s', 148462), ('t', 137277), ('l', 122431), ('c', 89367)]\n",
      "Top 10 letters by presence in words: [('e', 154827), ('i', 134627), ('a', 133659), ('r', 120548), ('n', 114976), ('o', 111416), ('s', 110214), ('t', 108416), ('l', 97083), ('c', 75526)]\n",
      "Average vowel ratio per word: 0.39\n",
      "Top 10 first letters: [('s', 24643), ('p', 19955), ('c', 18873), ('a', 15016), ('m', 12302), ('t', 12295), ('u', 11834), ('b', 11719), ('d', 11096), ('r', 10334)]\n",
      "Top 10 last letters: [('s', 41635), ('e', 33665), ('d', 23114), ('y', 20367), ('n', 17260), ('g', 12958), ('t', 12609), ('r', 12559), ('a', 11219), ('l', 10466)]\n",
      "Top 10 start bigrams: [('un', 10250), ('co', 6220), ('re', 5742), ('pr', 5201), ('no', 4661), ('in', 4249), ('ca', 3777), ('su', 3751), ('de', 3687), ('se', 3505)]\n",
      "Top 10 end bigrams: [('ed', 17572), ('ng', 12128), ('es', 9802), ('ly', 8958), ('er', 8947), ('ic', 6909), ('on', 6710), ('ss', 6656), ('al', 6549), ('le', 5893)]\n",
      "Suffix counts (selected): [('s', 41635), ('ed', 17572), ('ing', 11703), ('ly', 8958), ('er', 8947), ('al', 6549), ('ness', 5006), ('tion', 3781), ('ous', 3691), ('ers', 2568)]\n",
      "Top 10 VC-shapes: [('CVCCVC', 4708), ('CVCCVCC', 3690), ('CVCCVCVC', 2620), ('CVCVC', 2557), ('CVCVCVC', 2357), ('CVCVCV', 1812), ('CVCVCC', 1779), ('CVCCVCVCC', 1758), ('CVCVCVCC', 1744), ('CVCCVCV', 1715)]\n",
      "Lowest-entropy (L, pos) slots (best to guess positionally): [(27, 3, -0.0), (27, 4, -0.0), (27, 14, -0.0), (28, 0, -0.0), (28, 1, -0.0), (28, 2, -0.0), (28, 3, -0.0), (28, 4, -0.0), (28, 5, -0.0), (28, 6, -0.0)]\n",
      "[('s', 1115), ('a', 885), ('c', 810), ('b', 785), ('t', 669), ('m', 624), ('p', 612), ('d', 588), ('l', 535), ('r', 494)]\n",
      "[4.324, 3.746, 4.244, 4.279, 4.251, 3.939, 3.82, 3.7]\n",
      "[0.239, 0.563, 0.312, 0.377, 0.387, 0.43, 0.368, 0.508, 0.484, 0.221]\n",
      "[('CVCCVC', 4708), ('CVCCVCC', 3690), ('CVCCVCVC', 2620), ('CVCVC', 2557), ('CVCVCVC', 2357), ('CVCVCV', 1812), ('CVCVCC', 1779), ('CVCCVCVCC', 1758), ('CVCVCVCC', 1744), ('CVCCVCV', 1715)]\n",
      "0 candidates\n",
      "No candidates, so no positional counts\n"
     ]
    }
   ],
   "source": [
    "def run_hangman_eda(filepath=\"words_250000_train.txt\"):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        words = [w.strip().lower() for w in f if w.strip()]\n",
    "    N = len(words)\n",
    "    lengths = [len(w) for w in words]\n",
    "    length_counter = Counter(lengths)\n",
    "    min_len, max_len, avg_len = min(lengths), max(lengths), sum(lengths) / N\n",
    "    print(f\"Total words: {N}\")\n",
    "    print(f\"Word length: min={min_len}, max={max_len}, avg={avg_len:.2f}\")\n",
    "    print(\"Most common lengths:\", length_counter.most_common(10))\n",
    "\n",
    "    global_letter_counter = Counter(\"\".join(words))\n",
    "    print(\"Top 10 letters by global frequency:\", global_letter_counter.most_common(10))\n",
    "\n",
    "    presence_counter = Counter()\n",
    "    for w in words: presence_counter.update(set(w))\n",
    "    print(\"Top 10 letters by presence in words:\", presence_counter.most_common(10))\n",
    "\n",
    "    vowels = set(\"aeiou\")\n",
    "    vowel_ratio = [sum(ch in vowels for ch in w)/len(w) for w in words]\n",
    "    avg_vowel_ratio = sum(vowel_ratio)/N\n",
    "    print(f\"Average vowel ratio per word: {avg_vowel_ratio:.2f}\")\n",
    "\n",
    "    bins = [i/20 for i in range(21)]\n",
    "    def bin_idx(x):\n",
    "        for i in range(len(bins)-1):\n",
    "            if bins[i] <= x < bins[i+1]: return i\n",
    "        return len(bins)-2\n",
    "    vr_bin_buckets = [[] for _ in range(len(bins)-1)]\n",
    "    for w, vr in zip(words, vowel_ratio): vr_bin_buckets[bin_idx(vr)].append(w)\n",
    "\n",
    "    pos_counts_by_len = {L: [Counter() for _ in range(L)] for L in length_counter}\n",
    "    for w in words:\n",
    "        for j, ch in enumerate(w): pos_counts_by_len[len(w)][j][ch] += 1\n",
    "\n",
    "    def entropy_from_counter(cntr):\n",
    "        total = sum(cntr.values())\n",
    "        return -sum((v/total)*math.log2(v/total) for v in cntr.values()) if total else 0.0\n",
    "\n",
    "    vowel_prob_by_len_pos, entropy_by_len_pos = {}, {}\n",
    "    for L, counters in pos_counts_by_len.items():\n",
    "        vowel_prob_by_len_pos[L] = [(sum(v for ch,v in c.items() if ch in vowels)/sum(c.values())) if sum(c.values()) else 0.0 for c in counters]\n",
    "        entropy_by_len_pos[L] = [entropy_from_counter(c) for c in counters]\n",
    "\n",
    "    first_letter_counter = Counter(w[0] for w in words)\n",
    "    last_letter_counter  = Counter(w[-1] for w in words)\n",
    "    print(\"Top 10 first letters:\", first_letter_counter.most_common(10))\n",
    "    print(\"Top 10 last letters:\",  last_letter_counter.most_common(10))\n",
    "\n",
    "    start_bigram_counter = Counter(w[:2] for w in words if len(w)>=2)\n",
    "    end_bigram_counter   = Counter(w[-2:] for w in words if len(w)>=2)\n",
    "    print(\"Top 10 start bigrams:\", start_bigram_counter.most_common(10))\n",
    "    print(\"Top 10 end bigrams:\",   end_bigram_counter.most_common(10))\n",
    "\n",
    "    common_suffixes = [\"ing\",\"ed\",\"ly\",\"tion\",\"s\",\"er\",\"ers\",\"est\",\"al\",\"ment\",\"ness\",\"ity\",\"ies\",\"able\",\"ous\"]\n",
    "    suffix_hits = {suf: sum(w.endswith(suf) for w in words) for suf in common_suffixes}\n",
    "    print(\"Suffix counts (selected):\", sorted(suffix_hits.items(), key=lambda x: -x[1])[:10])\n",
    "\n",
    "    pre_suffix_letter = {suf: Counter() for suf in common_suffixes}\n",
    "    for w in words:\n",
    "        for suf in common_suffixes:\n",
    "            if w.endswith(suf) and len(w) > len(suf):\n",
    "                pre_suffix_letter[suf][w[-len(suf)-1]] += 1\n",
    "\n",
    "    presence_by_len = {L: Counter() for L in length_counter}\n",
    "    for w in words: presence_by_len[len(w)].update(set(w))\n",
    "\n",
    "    prob_vowel_by_vr_bin = [(sum(sum(ch in vowels for ch in w) for w in bucket) / (sum(len(w) for w in bucket) or 1)) for bucket in vr_bin_buckets]\n",
    "\n",
    "    def pattern_position_counters(pattern):\n",
    "        rx = re.compile('^' + pattern.strip('^$') + '$')\n",
    "        cand = [w for w in words if rx.match(w)]\n",
    "        if not cand: return [], Counter(), []\n",
    "        L = len(cand[0])\n",
    "        pos_cnts = [Counter() for _ in range(L)]\n",
    "        for w in cand:\n",
    "            for j, ch in enumerate(w): pos_cnts[j][ch] += 1\n",
    "        return cand, Counter(\"\".join(cand)), pos_cnts\n",
    "\n",
    "    char_class_shape = lambda w: \"\".join(\"V\" if ch in vowels else \"C\" for ch in w)\n",
    "    shape_counter = Counter(char_class_shape(w) for w in words)\n",
    "    print(\"Top 10 VC-shapes:\", shape_counter.most_common(10))\n",
    "\n",
    "    interesting = sorted((H,L,j) for L,Hs in entropy_by_len_pos.items() for j,H in enumerate(Hs))\n",
    "    print(\"Lowest-entropy (L, pos) slots (best to guess positionally):\",\n",
    "          [(L, j, round(H,3)) for H,L,j in interesting[:10]])\n",
    "\n",
    "    return dict(\n",
    "        words=words,\n",
    "        length_counter=length_counter,\n",
    "        global_letter_counter=global_letter_counter,\n",
    "        presence_counter=presence_counter,\n",
    "        pos_counts_by_len=pos_counts_by_len,\n",
    "        vowel_prob_by_len_pos=vowel_prob_by_len_pos,\n",
    "        entropy_by_len_pos=entropy_by_len_pos,\n",
    "        first_letter_counter=first_letter_counter,\n",
    "        last_letter_counter=last_letter_counter,\n",
    "        start_bigram_counter=start_bigram_counter,\n",
    "        end_bigram_counter=end_bigram_counter,\n",
    "        suffix_hits=suffix_hits,\n",
    "        pre_suffix_letter=pre_suffix_letter,\n",
    "        presence_by_len=presence_by_len,\n",
    "        prob_vowel_by_vr_bin=prob_vowel_by_vr_bin,\n",
    "        bins=bins,\n",
    "        shape_counter=shape_counter,\n",
    "        pattern_position_counters=pattern_position_counters\n",
    "    )\n",
    "\n",
    "\n",
    "models = run_hangman_eda(\"words_250000_train.txt\")\n",
    "L = 5\n",
    "print(models[\"pos_counts_by_len\"][L][0].most_common(10))\n",
    "print([round(h,3) for h in models[\"entropy_by_len_pos\"][8]])\n",
    "print([round(p,3) for p in models[\"vowel_prob_by_len_pos\"][10]])\n",
    "print(models[\"shape_counter\"].most_common(10))\n",
    "cands, agg, poscnts = models[\"pattern_position_counters\"](\".pp.e\")\n",
    "print(f\"{len(cands)} candidates\")\n",
    "if poscnts:  # only if not empty\n",
    "    print(\"Top letters at pos 0:\", poscnts[0].most_common(5))\n",
    "else:\n",
    "    print(\"No candidates, so no positional counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844467bf-1d8a-4597-90bb-18a3c5eda637",
   "metadata": {},
   "source": [
    "The dictionary contains ~227k words with an average length of 9.35, and most words fall in the 7–11 letter range. This means the game is rarely about very short words, and strategies should be optimized for medium-length words. Letter frequency analysis shows that `e, a, i, o, n, r, s, t, l` dominate both in raw counts and word presence, making them strong candidates for early guesses. On average, 39% of characters in words are vowels, reinforcing the value of opening with high-frequency vowels such as `e, a, i, o`.\n",
    "\n",
    "Beyond global frequency, positional and morphological patterns offer additional leverage. Common first letters include `s, p, c, a, m`, while the most common last letters are `s, e, d, y, n`. Frequent suffixes such as `-s, -ed, -ing, -ly, -er, -al` mean that once part of a word is revealed, common endings can often be predicted. Likewise, bigram patterns like `un-, co-, re-, pr-` at the start and `-ed, -ing, -ly, -er` at the end can significantly reduce candidate space.\n",
    "\n",
    "Entropy analysis shows that some positions (especially in long words) are highly predictable, while in typical 7–12 letter words, guessing yields ~3.7–4.3 bits of information, enough to meaningfully prune the dictionary. This suggests an optimal strategy: start with high-presence letters for coverage, then pivot to entropy-driven guesses guided by positional probabilities, prefixes, and suffixes. Combining global frequency with structural cues maximizes efficiency in solving Hangman.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f772420-ce2a-4e1e-b365-6aa501563bb4",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a67ad6-abbb-4d87-a32b-e9c0f55a39f0",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838acf3d-b895-433e-8df1-3295c22caa70",
   "metadata": {},
   "source": [
    "This code loads a word list, then computes bigram probabilities \n",
    "𝑃\n",
    "(\n",
    "𝑛\n",
    "𝑒\n",
    "𝑥\n",
    "𝑡\n",
    "∥\n",
    "𝑐\n",
    "𝑢\n",
    "𝑟\n",
    "𝑟\n",
    "𝑒\n",
    "𝑛\n",
    "𝑡\n",
    ")\n",
    "P(next∥current) for all letters and positional letter probabilities by word length and character position. It outputs the most likely successors for specific letters (e.g., q, t), the most common starting letters of 5-letter words, the most common ending letters of 8-letter words, and a probability distribution of starting letters in 7-letter words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09a5e84d-57f5-4168-b6dd-fd4c8a015f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 227300\n",
      "P(next|q): [('u', 0.9764556962025317), ('a', 0.005063291139240506), ('i', 0.0027848101265822785), ('s', 0.002531645569620253), ('t', 0.0012658227848101266)]\n",
      "P(next|t): [('i', 0.22135592132704462), ('e', 0.21031058491353033), ('o', 0.10132511951743832), ('a', 0.09957647511791318), ('r', 0.09310328231783617)]\n",
      "5-letter words, pos 0: [('s', 0.09890012417952812), ('a', 0.07849920170303352), ('c', 0.07184672698243746), ('b', 0.06962923540890545), ('t', 0.05934007450771687), ('m', 0.05534858967535923), ('p', 0.054284193720063864), ('d', 0.052155401809473124), ('l', 0.04745431967358524), ('r', 0.043817633492992725)]\n",
      "8-letter words, last pos: [('s', 0.20116905293576776), ('e', 0.15591750952318403), ('d', 0.10462367003809274), ('n', 0.07536450807828714), ('t', 0.06692499671614344), ('r', 0.06081702351241298), ('y', 0.05924077236306318), ('a', 0.050768422435308026), ('g', 0.04965191120451859), ('l', 0.04016156574280835)]\n",
      "\n",
      "7-letter words, position 0 probabilities:\n",
      "       prob\n",
      "s  0.106328\n",
      "c  0.086134\n",
      "p  0.071836\n",
      "b  0.069292\n",
      "a  0.067443\n",
      "m  0.058232\n",
      "t  0.056690\n",
      "d  0.052413\n",
      "r  0.050447\n",
      "g  0.041082\n",
      "f  0.039579\n",
      "l  0.038539\n",
      "h  0.037421\n",
      "e  0.036303\n",
      "w  0.028634\n"
     ]
    }
   ],
   "source": [
    "with open(\"words_250000_train.txt\") as f:\n",
    "    words = [w.strip().lower() for w in f if w.strip().isalpha()]\n",
    "\n",
    "alphabet = sorted(set(\"\".join(words)))\n",
    "P_next = {a: Counter() for a in alphabet}\n",
    "positional_counts = defaultdict(lambda: defaultdict(Counter))\n",
    "\n",
    "for w in words:\n",
    "    for a, b in zip(w, w[1:]):\n",
    "        P_next[a][b] += 1\n",
    "    L = len(w)\n",
    "    for i, ch in enumerate(w):\n",
    "        positional_counts[L][i][ch] += 1\n",
    "\n",
    "P_next = {a: {b: c / sum(cnt.values()) for b, c in cnt.items()} for a, cnt in P_next.items()}\n",
    "positional_probs = {L: {i: {ch: c / sum(cnt.values()) for ch, c in cnt.items()} for i, cnt in posdict.items()} for L, posdict in positional_counts.items()}\n",
    "\n",
    "print(\"Total words:\", len(words))\n",
    "print(\"P(next|q):\", Counter(P_next['q']).most_common(5))\n",
    "print(\"P(next|t):\", Counter(P_next['t']).most_common(5))\n",
    "print(\"5-letter words, pos 0:\", Counter(positional_probs[5][0]).most_common(10))\n",
    "print(\"8-letter words, last pos:\", Counter(positional_probs[8][7]).most_common(10))\n",
    "\n",
    "df = pd.DataFrame.from_dict(positional_probs[7][0], orient=\"index\", columns=[\"prob\"]).sort_values(\"prob\", ascending=False)\n",
    "print(\"\\n7-letter words, position 0 probabilities:\")\n",
    "print(df.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382d0e77-960d-4dda-bb9a-b5e0c29fa943",
   "metadata": {},
   "source": [
    "The dataset contains 227,300 words, allowing us to study strong structural patterns in English spelling. Bigram analysis shows that “q” is followed by “u” nearly 98% of the time, reflecting a strict orthographic rule. In contrast, “t” has a more varied distribution, most frequently followed by i (22%), e (21%), o (10%), a (10%), and r (9%). These results highlight how some letters have near-deterministic successors while others branch into multiple plausible continuations.\n",
    "\n",
    "Positional analysis reveals further trends in word structure. For example, 5-letter words most often start with “s” (~10%), while 8-letter words commonly end with “s” (20%) or “e” (16%), reflecting pluralization and common suffix patterns. Similarly, 7-letter words most often begin with “s” (10.6%), followed by c, p, and b. Overall, “s” dominates both word openings and endings, while vowels like a and e consistently play key roles in shaping English word forms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ee3c8d-59e6-451a-883a-8e0831b10f65",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2682da1a-cce3-460f-8164-12747b4cf039",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df16536-49ef-4625-a08a-a94713a0de2c",
   "metadata": {},
   "source": [
    "This code builds three probabilistic models from a training dictionary—global letter frequency, positional letter probabilities by word length, and conditional bigram probabilities—and combines them to rank the most likely next letters in a Hangman word mask. Given a partially known word and previously guessed letters, it filters candidate matches, scores possible letters using weighted contributions from the three models, and returns the most probable guesses in ranked order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f0bf3c3-a5ac-4429-96f1-7d48b885aa9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('l', 0.3588004776920135), ('c', 0.1354456894657407), ('e', 0.10339238268283653), ('p', 0.10055900657696656), ('t', 0.05048149786477887), ('n', 0.04326046046833981), ('k', 0.02715538630931846), ('y', 0.023987179320744283), ('f', 0.01738095062757769)]\n"
     ]
    }
   ],
   "source": [
    "def build_positional_model(words):\n",
    "    max_len = max(map(len, words))\n",
    "    pos_counter = defaultdict(lambda: [Counter() for _ in range(max_len)])\n",
    "    for w in words:\n",
    "        for i, ch in enumerate(w):\n",
    "            pos_counter[len(w)][i][ch] += 1\n",
    "    return {L: [{c: n/sum(cnt.values()) for c, n in cnt.items()} \n",
    "                for cnt in counters] for L, counters in pos_counter.items()}\n",
    "\n",
    "def build_bigram_model(words):\n",
    "    counts = defaultdict(Counter)\n",
    "    for w in words:\n",
    "        for a, b in zip(w, w[1:]):\n",
    "            counts[a][b] += 1\n",
    "    return {a: {b: n/sum(cnt.values()) for b, n in cnt.items()} for a, cnt in counts.items()}\n",
    "\n",
    "def guess_next_letter(mask, words, guessed, pos_prob, bigram_prob, global_freq, alpha=0.5, beta=0.3, gamma=0.2):\n",
    "    regex = re.compile(\"^\" + mask.replace(\"_\", \".\") + \"$\")\n",
    "    candidates = [w for w in words if regex.match(w)]\n",
    "    if not candidates: return []\n",
    "    L, scores = len(mask), Counter()\n",
    "    for w in candidates:\n",
    "        for i, ch in enumerate(w):\n",
    "            if mask[i] == \"_\" and ch not in guessed:\n",
    "                g = global_freq.get(ch, 0)\n",
    "                p = pos_prob.get(L, [{}])[i].get(ch, 0)\n",
    "                b = 0\n",
    "                if i > 0 and mask[i-1] != \"_\": b = bigram_prob.get(mask[i-1], {}).get(ch, 0)\n",
    "                elif i < L-1 and mask[i+1] != \"_\": b = bigram_prob.get(ch, {}).get(mask[i+1], 0)\n",
    "                scores[ch] += alpha*g + beta*p + gamma*b\n",
    "    return scores.most_common()\n",
    "\n",
    "global_freq = Counter(\"\".join(words))\n",
    "total = sum(global_freq.values())\n",
    "global_freq = {c: v/total for c, v in global_freq.items()}\n",
    "pos_prob = build_positional_model(words)\n",
    "bigram_prob = build_bigram_model(words)\n",
    "mask, guessed = \"__pp_e\", {\"a\",\"i\",\"o\",\"u\",\"s\"}\n",
    "print(guess_next_letter(mask, words, guessed, pos_prob, bigram_prob, global_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5382191-bbb0-4bf0-9e4e-52469053fb0d",
   "metadata": {},
   "source": [
    "The probability distribution shows that, given the current constraints of our Hangman model, the letter ‘l’ dominates as the most likely candidate (≈36%), followed by ‘c’, ‘e’, and ‘p’, each contributing meaningfully but at much lower levels. This indicates that the model effectively narrows the search space, heavily weighting certain letters when strong positional and contextual signals are present. In the broader context of Hangman, such skewed distributions suggest the model can prioritize highly probable guesses early, improving efficiency, but may also risk overconfidence if the dominant letter proves incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dbce2f-ff73-4eca-9cf1-90e80b7e60b9",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179619a2-06af-4d07-b7fd-a9507e81b6a1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec2da93-3d44-4839-8fea-01f61361b4f8",
   "metadata": {},
   "source": [
    "This code computes the vowel-to-length ratio for all words longer than two letters, then summarizes the distribution with mean, median, and high percentiles (95th, 99th). It prints these statistics and visualizes the distribution using a histogram with reference lines marking the mean and percentile thresholds. In effect, it quantifies and illustrates how heavily words in the dictionary rely on vowels relative to their length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b61ceda3-1942-41b2-af53-97b29d31dd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.387\n",
      "Median: 0.385\n",
      "95th: 0.545\n",
      "99th: 0.600\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAHFCAYAAAAHcXhbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABriklEQVR4nO3deXxM1/sH8M/sM1kJIhEksZRaaq0iJdReWmtpqQpaVbRVpYTW1uJbVFUtLS2xL7XVD609lqK1RRW1iyBpgmZPZr2/PzS3HVlkbmYymfF5v17z6p17z5l55jbJPM459z4yQRAEEBEREbkoubMDICIiIioKJjNERETk0pjMEBERkUtjMkNEREQujckMERERuTQmM0REROTSmMwQERGRS2MyQ0RERC6NyQwRERG5NCYzRDbq3r07dDodkpOT823Tr18/qFQq/PXXX8UXWAGio6Mhk8kQHR1dqHY5D4VCgXLlyuGll17CyZMnJb//woULERUVlWv/zZs3IZPJ8jwm1aPxly5dGvXq1cPbb7+N48eP2y2GNWvWYO7cuTb1yeu9Jk+eDJlMhnv37tn0WgW5cOECJk+ejJs3b+Y6FhERgZCQELu9F1FJwGSGyEaDBw9GdnY21qxZk+fxlJQUbNmyBV26dEH58uWLOTr7mD59Oo4dO4bo6Gh88sknOHr0KMLDw3HlyhVJr5dfMhMYGIhjx46hc+fORYzYWq9evXDs2DEcOXIE69atwxtvvIHjx4+jWbNmeP/99+0Sg5RkxlGf91EXLlzAlClT8kxmPvnkE2zZssWh709U3JTODoDI1XTq1AkVKlTA0qVLMWzYsFzH165di6ysLAwePNgJ0dlH9erV0bRpUwBAixYtUKpUKQwYMACrVq3ClClT7PY+Go1GfB97Kl++vNXrdujQASNHjsSQIUMwb9481KxZE++8845DY/gvs9kMk8lULO/1OFWrVnXq+xM5AkdmiGykUCgwYMAAnDp1CufOnct1fNmyZQgMDESnTp0AAH/88Qe6du2K0qVLQ6vVon79+li+fLnYXhAElC9fHsOHDxf3mc1mlC5dGnK53Gqqas6cOVAqlVZTXCdPnsTLL78MPz8/aLVaNGjQABs2bLDrZ27cuDEA5Jo2mzJlCp577jn4+fnBx8cHDRs2xPfff4//1q8NCQnB+fPncfDgQXH6J2eaI78pniNHjqBNmzbw9vaGh4cHmjdvjh07dhTpMygUCsyfPx9ly5bFrFmzxP15xZCUlIQhQ4agUqVK0Gg0KFeuHMLCwrB3714AQKtWrbBjxw7ExsZaTWv99/VmzpyJzz77DKGhodBoNDhw4ECBU1pxcXHo0aMHfHx84Ovri9dffx1JSUlWbWQyGSZPnpyrb0hICCIiIgAAUVFReOWVVwAArVu3FmPLec+8ppmys7MRGRmJ0NBQqNVqBAUFYfjw4bmmUkNCQtClSxf8/PPPaNiwIXQ6HWrWrImlS5c+5uwTORaTGSIJBg0aBJlMluuP+IULF/Dbb79hwIABUCgUuHTpEpo3b47z589j3rx52Lx5M2rVqoWIiAjMnDkTwMMvqBdeeEH8ogQeJijJycnQarXYt2+fuH/v3r1o1KgRSpUqBQA4cOAAwsLCkJycjG+++QY//vgj6tevjz59+th1HcqNGzcAAE899ZTV/ps3b+Ltt9/Ghg0bsHnzZvTo0QPvvvsuPv30U7HNli1bUKVKFTRo0ADHjh3DsWPHCpzmOHjwIF544QWkpKTg+++/x9q1a+Ht7Y2XXnoJ69evL9Ln0Ol0aNu2LW7cuIHbt2/n265///7YunUrJk6ciN27d+O7775D27Ztcf/+fQAPp83CwsIQEBAgfqZjx45Zvca8efOwf/9+zJ49Gz/99BNq1qxZYGzdu3dHtWrVsHHjRkyePBlbt25Fhw4dYDQabfqMnTt3xvTp0wEACxYsEGPLb2pLEAR069YNs2fPRv/+/bFjxw6MGjUKy5cvxwsvvAC9Xm/V/uzZs/jwww/xwQcf4Mcff8QzzzyDwYMH49ChQzbFSWRXAhFJEh4eLpQtW1YwGAzivg8//FAAIFy+fFkQBEF49dVXBY1GI9y6dcuqb6dOnQQPDw8hOTlZEARB+O677wQAYrvPPvtMqFmzpvDyyy8LAwcOFARBEAwGg+Dp6SmMHz9efJ2aNWsKDRo0EIxGo9Xrd+nSRQgMDBTMZrMgCIJw4MABAYBw4MCBAj9TTrv169cLRqNRyMzMFH755RehRo0aQq1atYS///47375ms1kwGo3C1KlThTJlyggWi0U8Vrt2bSE8PDxXnxs3bggAhGXLlon7mjZtKvj7+wtpaWniPpPJJNSpU0eoWLGi1evmBYAwfPjwfI+PHTtWACD8+uuv+cbg5eUljBw5ssD36dy5sxAcHJzvZ6patarVz0Z+7zVp0iQBgPDBBx9YtV29erUAQFi1apXVZ5s0aVKu9wwODhYGDBggPv/hhx/y/f89YMAAq7h//vlnAYAwc+ZMq3br168XAAiLFy+2eh+tVivExsaK+7KysgQ/Pz/h7bffzvVeRMWFIzNEEg0ePBj37t3Dtm3bAAAmkwmrVq1CixYtUL16dQDA/v370aZNG1SqVMmqb0REBDIzM8V/zbdt2xYAxNGZPXv2oF27dmjbti327NkDADh27BgyMjLEtlevXsWff/6Jfv36ie+f83jxxRcRHx+PS5cuSfpsffr0gUqlgoeHB8LCwpCamoodO3aII0I59u/fj7Zt28LX1xcKhQIqlQoTJ07E/fv3kZiYaPP7ZmRk4Ndff0WvXr3g5eUl7lcoFOjfvz9u374t+TPlEP4zBZafJk2aICoqCp999hmOHz9u8+gIALz88stQqVSFbp/z/zFH7969oVQqceDAAZvf2xb79+8HAHGaKscrr7wCT09Pq5FBAKhfvz4qV64sPtdqtXjqqacQGxvr0DiJCsJkhkiiXr16wdfXF8uWLQMA7Ny5E3/99ZfVwt/79+8jMDAwV98KFSqIxwEgODgYVatWxd69e8UkJyeZyfkC37t3L3Q6HZo3bw7g3/Uro0ePhkqlsnrkLEyWernv559/jhMnTuDgwYOYMGEC/vrrL3Tr1s1qyuG3335D+/btAQBLlizBL7/8ghMnTmDChAkAgKysLJvf9++//4YgCIU6Z1LlfOnmvF5e1q9fjwEDBuC7775Ds2bN4OfnhzfeeAMJCQmFfp+8PkNBAgICrJ4rlUqUKVOmyJ/3ce7fvw+lUoly5cpZ7ZfJZAgICMj1/mXKlMn1GhqNRtL/byJ74dVMRBLpdDq89tprWLJkCeLj47F06VJ4e3uLiy+Bh3/44+Pjc/W9e/cuAKBs2bLivjZt2uDHH3/EwYMHYbFY0KpVK3h7e6NChQrYs2cP9u7dixYtWkCj0Vj1jYyMRI8ePfKMsUaNGpI+W5UqVcRFvy1btoROp8PHH3+Mr7/+GqNHjwYArFu3DiqVCtu3b4dWqxX7bt26VdJ7AhAXPRf2nNkqKysLe/fuRdWqVVGxYsV825UtWxZz587F3LlzcevWLWzbtg3jxo1DYmIifv7550K9V86C4MJKSEhAUFCQ+NxkMuH+/ftWyYNGo8m1hgUoWoJXpkwZmEwmJCUlWSU0giAgISEBzz77rOTXJiouHJkhKoLBgwfDbDZj1qxZ2LlzJ1599VV4eHiIx9u0aYP9+/eLX8Q5VqxYAQ8PD6vLdNu2bYu//voLc+fORdOmTeHt7S2+xpYtW3DixAlxigl4mKhUr14dZ8+eRePGjfN85LxGUX300UeoVq0a/ve//yEtLQ3Awy9rpVIJhUIhtsvKysLKlStz9S/sv9w9PT3x3HPPYfPmzVbtLRYLVq1ahYoVK+ZahFxYZrMZI0aMwP379zF27NhC96tcuTJGjBiBdu3a4fTp0+J+e49GrF692ur5hg0bYDKZ0KpVK3FfSEgIfv/9d6t2+/fvR3p6utW+nIS3MPG1adMGALBq1Sqr/Zs2bUJGRoZ4nKgk48gMURE0btwYzzzzDObOnQtBEHLdW2bSpEnYvn07WrdujYkTJ8LPzw+rV6/Gjh07MHPmTPj6+optX3jhBchkMuzevdvqXi5t27bFgAEDxO3/+vbbb9GpUyd06NABERERCAoKwoMHD3Dx4kWcPn0aP/zwg10+p0qlwvTp09G7d2989dVX+Pjjj9G5c2fMmTMHffv2xZAhQ3D//n3Mnj1b/CL9r7p162LdunVYv349qlSpAq1Wi7p16+b5XjNmzEC7du3QunVrjB49Gmq1GgsXLsQff/yBtWvXFmrE46+//sLx48chCALS0tLwxx9/YMWKFTh79iw++OADvPXWW/n2TUlJQevWrdG3b1/UrFkT3t7eOHHiBH7++WerEbC6deti8+bNWLRoERo1agS5XC6OZkmxefNmKJVKtGvXDufPn8cnn3yCevXqoXfv3mKb/v3745NPPsHEiRMRHh6OCxcuYP78+VY/RwBQp04dAMDixYvh7e0NrVaL0NDQPKeI2rVrhw4dOmDs2LFITU1FWFgYfv/9d0yaNAkNGjRA//79JX8momLj1OXHRG7gq6++EgAItWrVyvP4uXPnhJdeeknw9fUV1Gq1UK9ePaurWf6rQYMGAgDhl19+EffduXNHAJDrCqEcZ8+eFXr37i34+/sLKpVKCAgIEF544QXhm2++EdvYejXTDz/8kOfx5557TihdurR4FdbSpUuFGjVqCBqNRqhSpYowY8YM4fvvvxcACDdu3BD73bx5U2jfvr3g7e0tABCvpsnr6h5BEITDhw8LL7zwguDp6SnodDqhadOmwv/93/8VGHsOAOJDLpcLPj4+Qt26dYUhQ4YIx44dy9X+0Riys7OFoUOHCs8884zg4+Mj6HQ6oUaNGsKkSZOEjIwMsd+DBw+EXr16CaVKlRJkMpmQ8+c05/VmzZr12PcShH+vZjp16pTw0ksvCV5eXoK3t7fw2muvCX/99ZdVf71eL3z00UdCpUqVBJ1OJ4SHhwsxMTG5rmYSBEGYO3euEBoaKigUCqv3fPRqJkF4eEXS2LFjheDgYEGlUgmBgYHCO++8k+vqteDgYKFz5865Pld4eHieV6sRFReZIBRiaT8RERFRCcU1M0REROTSmMwQERGRS2MyQ0RERC6NyQwRERG5NCYzRERE5NKYzBAREZFLc/ub5lksFty9exfe3t42316ciIiInEP456aXFSpUgFxe8NiL2yczd+/ezVWxmIiIiFxDXFxcgbXUgCcgmcmpTRMXFwcfHx8nR0PkXBkZQE6x6Lt3AU9P58ZDRJSf1NRUVKpUqVA15tw+mcmZWvLx8WEyQ0+8/9SEhI8PkxkiKvkKs0TE7ZMZInpyGAwGfPXVVwCA999/H2q12rb+ZgO+Ov5P/6bvQ62wrT8ROYfb12ZKTU2Fr68vUlJSODJDT7yMDMDL6+F2err7jcxkZGTA658PmJ6eDk8bP2CGIQNeM/7pH5kOT7WbnSAiF2LL9zdHZojIbSiVSgwYMEDctrm/XIkB9QaI20TkGjgyQ/QEcfeRGXI8s9kMo9Ho7DDIDahUKij+u5DvERyZISIiuxIEAQkJCUhOTnZ2KORGSpUqhYCAgCLfB47JDBERPVZOIuPv7w8PDw/ehJSKRBAEZGZmIjExEQAQGBhYpNdjMkNEbiMjIwNBQUEAgDt37khaABw055/+o+5wAfA/zGazmMiUKVPG2eGQm9DpdACAxMRE+Pv7Fzjl9DhMZojIraSkpBStv75o/d1RzhoZDw8PJ0dC7ibnZ8poNDKZISICHv5L7/Lly+K2zf1VOlwecVncJmucWiJ7s9fPFJMZInIbcrkc1atXl95fJkf1MtL7E5FzFFyGkoiIiKiEYzJDRG7DaDRiwYIFWLBggaR7oRjNRiz4bQEW/LYARjPvpeIOIiIiIJPJMHTo0FzHhg0bBplMhoiIiOIPzAHOnTuH8PBw6HQ6BAUFYerUqXjcreRefvllVK5cGVqtFoGBgejfvz/u3r1r1Wbfvn1o3rw5vL29ERgYiLFjx8JkMjnyo9iMyQwRuQ2DwYARI0ZgxIgRMBgMtvc3GzDipxEY8dMIGMy296eSqVKlSli3bh2ysrLEfdnZ2Vi7di0qV67sxMjsJzU1Fe3atUOFChVw4sQJfP3115g9ezbmzJlTYL/WrVtjw4YNuHTpEjZt2oRr166hV69e4vHff/8dL774Ijp27IgzZ85g3bp12LZtG8aNG+foj2QTJjNE5DYUCgV69eqFXr16SboyQiFXoFetXuhVqxcUculXVlDJ0rBhQ1SuXBmbN28W923evBmVKlVCgwYNrNoKgoCZM2eiSpUq0Ol0qFevHjZu3CgeN5vNGDx4MEJDQ6HT6VCjRg2xuGmOiIgIdOvWDbNnz0ZgYCDKlCmD4cOHO/TOyatXr0Z2djaioqJQp04d9OjRA+PHj8ecOXMKHJ354IMP0LRpUwQHB6N58+YYN24cjh8/Lsa6bt06PPPMM5g4cSKqVauG8PBwzJgxAwsWLEBaWprDPo+tuACYqARJSkpCamqq1T4fHx+UK1fOSRG5Fq1Wix9++EF6f6UWP7wivf+TRBCAzMzif18PD0DKBTADBw7EsmXL0K9fPwDA0qVLMWjQIERHR1u1+/jjj7F582YsWrQI1atXx6FDh/D666+jXLlyCA8Ph8ViQcWKFbFhwwaULVsWR48exZAhQxAYGIjevXuLr3PgwAEEBgbiwIEDuHr1Kvr06YP69evjrbfeyjO+w4cPo1OnTgV+hvHjx2P8+PF5Hjt27BjCw8Oh0WjEfR06dEBkZCRu3ryJ0NDQx56jBw8eYPXq1WjevDlUKhUAQK/XQ6vVWrXT6XTIzs7GqVOn0KpVq8e+bnFgMkNUQiQlJWHQkKFIy8q22u+t02Lp4m+Y0FCJkpn5b52v4iS1plj//v3FL3aZTIZffvkF69ats0pmMjIyMGfOHOzfvx/NmjUDAFSpUgVHjhzBt99+i/DwcKhUKkyZMkXsExoaiqNHj2LDhg1WyUzp0qUxf/58KBQK1KxZE507d8a+ffvyTWYaN26MmJiYAj+Dn59fvscSEhIQEhJita98+fLisYKSmbFjx2L+/PnIzMxE06ZNsX37dvFYhw4dMHfuXKxduxa9e/dGQkICPvvsMwBAfHx8gfEWJyYzRCVEamoq0rKy0ar/OygTWBEAcD/+NqJXLkJqaiqTGaIiKFu2LDp37ozly5dDEAR07twZZcuWtWpz4cIFZGdno127dlb7DQaD1XTUN998g++++w6xsbHIysqCwWBA/fr1rfrUrl3baqozMDAQ586dyzc+nU6HatWqFeET5r5nS8700uPu5TJmzBgMHjwYsbGxmDJlCt544w1s374dMpkM7du3x6xZszB06FD0798fGo0Gn3zyCY4cOVKkm9zZm1PXzBw6dAgvvfQSKlSoAJlMhq1bt+bb9u2334ZMJsPcuXOLLT4iZygTWBEBwaEICA4VkxoqnMzMTAQFBSEoKAiZEuZAMo2ZCJoThKA5Qcg0OmEOxYV4eDwcJSnuR1FuQjxo0CBERUVh+fLlGDRoUK7jFosFALBjxw7ExMSIjwsXLojrZjZs2IAPPvgAgwYNwu7duxETE4OBAwfmWnCeM02TQyaTia+fl8OHD8PLy6vAx/Tp0/PtHxAQgISEBKt9OXWPckZo8lO2bFk89dRTaNeuHdatW4edO3fi+PHj4vFRo0YhOTkZt27dwr1799C1a1cAKNTUVXFx6shMRkYG6tWrh4EDB6Jnz575ttu6dSt+/fVXVKhQoRijIyJXIwiCeFnp4y5Jzbd/mvT+TxKZTNp0jzN17NhRTDo6dOiQ63itWrWg0Whw69YthIeH5/kahw8fRvPmzTFs2DBx37Vr14ocW1GnmZo1a4bx48fDYDBArVYDAHbv3o0KFSrkmn4qSM7PvV6vt9ovk8nE7+C1a9eiUqVKaNiwYaFf19Gcmsx06tTpsQue7ty5gxEjRmDXrl3o3LlzMUVGRK5Iq9XizJkz4rbN/ZVanHn7jLhN7kWhUODixYvi9qO8vb0xevRofPDBB7BYLHj++eeRmpqKo0ePwsvLCwMGDEC1atWwYsUK7Nq1C6GhoVi5ciVOnDhR5FGKok4z9e3bF1OmTEFERATGjx+PK1euYPr06Zg4caI4zfTbb7/hjTfewL59+xAUFITffvsNv/32G55//nmULl0a169fx8SJE1G1alVxzRAAzJo1Cx07doRcLsfmzZvxv//9Dxs2bChR00wles2MxWJB//79MWbMGNSuXbtQffR6vVVG+eiVIUTkvhQKRa61Czb1lytQP0B6fyr5fHx8Cjz+6aefwt/fHzNmzMD169dRqlQpNGzYULyKaOjQoYiJiUGfPn0gk8nw2muvYdiwYfjpp5+KI/x8+fr6Ys+ePRg+fDgaN26M0qVLY9SoURg1apTYJjMzE5cuXRIvu9bpdNi8eTMmTZqEjIwMBAYGomPHjli3bp3VVVE//fQTpk2bBr1ej3r16uHHH3987EBEcSvRycznn38OpVKJ9957r9B9ZsyYYbXSnIiInlxRUVEFHn90raZMJsN7772X7/eORqPBsmXLsGzZMqv9M2bMKPA9i2O9Z926dXHo0KF8j7dq1cpq+rRu3brYv3//Y1+3MG2crcTeNO/UqVP46quvEBUVZVNVzcjISKSkpIiPuLg4B0ZJRCWJ0WhEVFQUoqKiJJcziIqJQlRMFMsZELmQEjsyc/jwYSQmJlrdatpsNuPDDz/E3LlzcfPmzTz7aTQaq+ExInpyGAwGDBw4EADwyiuv5Lqi5LH9zQYM/PGf/rVegUphW38ico4Sm8z0798fbdu2tdrXoUMH9O/fX/xjRUT0XwqFAi+++KK4bXN/uQIvVn9R3CYi1+DUZCY9PR1Xr14Vn9+4cQMxMTHw8/ND5cqVUaZMGav2KpUKAQEBqFGjRnGHSkQuQKvVYseOHdL7K7XY0Vd6fyJyDqcmMydPnkTr1q3F5zmrrgcMGPDYRVtEREREgJOTmUdXVj9OfutkiIiI6MlVYq9mIiKyVWZmJqpXr47q1atLLmdQ/evqqP51dZYzIHIhJXYBMBGRrQRBENfhSS1ncPWB9P5E5BxMZojIbWi1Whw5ckTctrm/UosjA4+I20TkGpjMEJHbUCgUCAsLk95frkBYZen96ckyefJkbN269bEFIsnxuGaGiIjcVlpaGkaOHIng4GDodDo0b94cJ06csGoTEREBmUxm9WjatKlVG5lMlqv0gRQ3b95Ey5Yt4eXlhfDwcMTGxlod79y5MzZt2lTk9ymMhQsXIjQ0FFqtFo0aNcLhw4cLbB8dHZ3rPMlkMvz5559im5y79j/6yM7OduhnYTJDRG7DZDLhhx9+wA8//ACTyWR7f4sJP5z/AT+c/wEmi+39qeR58803sWfPHqxcuRLnzp1D+/bt0bZtW9y5c8eqXceOHREfHy8+du7c6ZB4PvzwQwQFBeHMmTMICAjA6NGjxWPr1q2DQqFAz549HfLe/7V+/XqMHDkSEyZMwJkzZ9CiRQt06tQJt27demzfS5cuWZ2r6tWrWx338fGxOh4fHy9p2tcWTGaIyG3o9Xr07t0bvXv3hl6vt72/SY/eG3uj98be0Jts708lS1ZWFjZt2oSZM2eiZcuWqFatGiZPnozQ0FAsWrTIqq1Go0FAQID48PPzE4+FhIQAALp37w6ZTCY+z7Fy5UqEhITA19cXr776KtLS0vKN6eLFixgwYACqV6+OiIgIXLhwAQCQnJyMjz/+GPPnz7fPh3+MOXPmYPDgwXjzzTfx9NNPY+7cuahUqVKu85IXf39/q3P16N22ZTKZ1fGAgABHfQwRkxkichtyuRzh4eEIDw+HXG77nze5TI7w4HCEB4dDLuOfx8LIMGQgw5BhdfWXwWxAhiEjV0KY09YiWMR9RrMRGYYMZJuyH9vWViaTCWazOdeogE6nExeK54iOjoa/vz+eeuopvPXWW0hMTBSP5UxLLVu2DPHx8VbTVNeuXcPWrVuxfft2bN++HQcPHsT//ve/fGOqV68e9u7dC4vFgt27d+OZZ54BAIwePRojRoywqkdYkKFDh8LLy6vAR36jLAaDAadOnUL79u2t9rdv3x5Hjx597Hs3aNAAgYGBaNOmDQ4cOJDreHp6OoKDg1GxYkV06dIFZ86cKdRnKgr+thKR29DpdIiOjkZ0dDR0Op3t/VU6REdEIzoiGjqV7f2fRF4zvOA1wwv3Mu+J+2b9MgteM7wwYucIq7b+s/3hNcMLt1L+/ZJdcGIBvGZ4YfC2wVZtQ74KgdcML1xMuig5Nm9vbzRr1gyffvop7t69C7PZjFWrVuHXX39FfHy82K5Tp05YvXo19u/fjy+++AInTpzACy+8II7ulStXDgBQqlQpBAQEiM8BwGKxICoqCnXq1EGLFi3Qv39/7Nu3L9+YZs+ejT///BMhISG4cuUKZs+ejUOHDuHs2bN444030Lt3b1SpUgVDhw6FwWDI93WmTp2KmJiYAh8VKlTIs++9e/dgNptRvnx5q/3ly5dHQkJCvu8ZGBiIxYsXY9OmTdi8eTNq1KiBNm3a4NChQ2KbmjVrIioqCtu2bcPatWuh1WoRFhaGK1eu5Pu69sCrmYiIyG2tXLkSgwYNQlBQEBQKBRo2bIi+ffvi9OnTYps+ffqI23Xq1EHjxo0RHByMHTt2oEePHgW+fkhICLy9vcXngYGBVqM6jwoKCsL27dvF53q9Hh06dMCKFSvw2WefwdvbG5cuXULHjh3x7bff4t13383zdfz9/eHv7//Yz18QmUxm9VwQhFz7/qtGjRpWtRGbNWuGuLg4zJ49Gy1btgQANG3a1GrxdFhYGBo2bIivv/4a8+bNK1K8BeHIDBERSZYemY70yHSU9Sgr7hsTNgbpkemY/6L1+o/E0YlIj0xHZd9/p1KGPzsc6ZHp+P7l763a3nz/JtIj0/F0uaeLFF/VqlVx8OBBpKenIy4uDr/99huMRiNCQ0Pz7RMYGIjg4OBCjSaoVCqr5zKZDBZL4afGpk2bhvbt26Nhw4aIjo5Gz549oVKp0KNHD0RHR+fbryjTTGXLloVCocg1CpOYmJhrtOZxmjZtWuB5ksvlePbZZzkyQ0RUWFlZWWjWrBkA4NixYzZPNWUZs9Ds+3/6Dz7GqaZC8FR75tqnVqihVqgL1ValUEGlUBWqbVF4enrC09MTf//9N3bt2oWZM2fm2/b+/fuIi4tDYGDgv3GqVDCbzXaN6eLFi1i7dq24psRsNsNoNAIAjEZjge83depUqyuh8pLfNJNarUajRo2wZ88edO/eXdy/Z88edO3a1abPcObMGavz9ChBEBATE4O6deva9Lq2YjJDRG7DYrHg7Nmz4rbN/QULzv51Vtwm17dr1y4IgoAaNWrg6tWrGDNmDGrUqIGBAwcCeLhYdfLkyejZsycCAwNx8+ZNjB8/HmXLlrX6og8JCcG+ffsQFhYGjUaD0qVLFykuQRAwZMgQfPnll/Dy8gLwcEpmyZIleOqpp7BixQq89tpr+fYv6jTTqFGj0L9/fzRu3BjNmjXD4sWLcevWLQwdOlRsExkZiTt37mDFihUAgLlz5yIkJAS1a9eGwWDAqlWrsGnTJqv74kyZMgVNmzZF9erVkZqainnz5iEmJgYLFiyQHGthMJkhIreh1Wqxe/ducdvm/kotdr++W9wm15eSkoLIyEjcvn0bfn5+6NmzJ6ZNmyZODykUCpw7dw4rVqxAcnIyAgMD0bp1a6xfv95qLcwXX3yBUaNGYcmSJQgKCsLNmzeLFNfixYtRvnx5dOnSRdw3efJk9O3bF8899xw6duyI4cOHF+k9CtKnTx/cv38fU6dORXx8POrUqYOdO3ciODhYbBMfH281VWUwGDB69GjcuXMHOp0OtWvXxo4dO/Diiy+KbZKTkzFkyBAkJCTA19cXDRo0wKFDh9CkSROHfRYAkAluXk0tNTUVvr6+SElJgY+Pj7PDIcrXtWvXMHj4e+j50TQEBD+cz0+IvYFNMyfg+wXzULVq1SK/R0YG8M8/ApGeDnjadySf3FR2djZu3Lgh3i2WyF4K+tmy5fubC4CJiIjIpXGaiYjchslkwq5duwAAHTp0gFJp2584k8WEXVf/6V+tA5Ry/okkcgX8TSUit6HX68U1COnp6TYnM3qTHl3W/tM/Mh1KNf9EErkC/qYSkduQy+Vo3LixuG1zf5kcjSs0FreJyDUwmSEit6HT6azq5tjcX6XDibek9yci5+A/PYiIiMilMZkhIiIil8ZkhojcRlZWFsLCwhAWFoasrCzb+xuzELY0DGFLw5BltL0/ETkH18wQkduwWCw4evSouG1zf8GCo3FHxW0icg1MZojIbWg0GmzZskXctrm/UoMtfbaI20QFmTx5MrZu3YqYmBhnh/LE4zQTEbkNpVKJbt26oVu3bjbfYwYAlHIlutXshm41u/GGeW4iLS0NI0eORHBwMHQ6HZo3b57rireIiAjIZDKrR9OmTa3ayGQybN26tcjx3Lx5Ey1btoSXlxfCw8MRGxtrdbxz585WhRsdaeHChWIZgUaNGuHw4cMFto+Ojs51nmQyGf7880+xTVRUVJ5tsrOzHfpZmMwQEZHbevPNN7Fnzx6sXLkS586dQ/v27dG2bVvcuXPHql3Hjh0RHx8vPnbu3OmQeD788EMEBQXhzJkzCAgIwOjRo8Vj69atg0KhQM+ePR3y3v+1fv16jBw5EhMmTMCZM2fQokULdOrUyaqwZH4uXbpkda6qV69uddzHx8fqeHx8vMNrejGZISK3YTabER0djejoaJjNZtv7W8yIvhmN6JvRMFts708lS1ZWFjZt2oSZM2eiZcuWqFatGiZPnozQ0FAsWrTIqq1Go0FAQID48PPzE4+FhIQAALp37w6ZTCY+z7Fy5UqEhITA19cXr776KtLS0vKN6eLFixgwYACqV6+OiIgIXLhwAcDDatMff/wx5s+fb58P/xhz5szB4MGD8eabb+Lpp5/G3LlzUalSpVznJS/+/v5W50qhUFgdl8lkVscDAgIc9TFETGaIyG1kZ2ejdevWaN26taRh7WxTNlovb43Wy1sj2+TYYXF3kZGRgYyMDAiCIO4zGAzIyMiAXq/Ps+1/F2cbjUZkZGTk+v+VV1tbmUwmmM3mXKMCOp0OR44csdoXHR0Nf39/PPXUU3jrrbeQmJgoHsuZllq2bBni4+OtpqmuXbuGrVu3Yvv27di+fTsOHjyI//3vf/nGVK9ePezduxcWiwW7d+/GM888AwAYPXo0RowYgcqVKxfqsw0dOhReXl4FPvIbZTEYDDh16hTat29vtb99+/biAvqCNGjQAIGBgWjTpg0OHDiQ63h6ejqCg4NRsWJFdOnSBWfOnCnUZyoKJjNE5DZkMhlq1aqFWrVqQSaTSetfrhZqlZPW/0mU88V57949cd+sWbPg5eWFESNGWLX19/fP9SW7YMECeHl5YfDgwVZtQ0JC4OXlhYsXL0qOzdvbG82aNcOnn36Ku3fvwmw2Y9WqVfj1118RHx8vtuvUqRNWr16N/fv344svvsCJEyfwwgsviMlYuXLlAAClSpVCQECA+Bx4eNVcVFQU6tSpgxYtWqB///7Yt29fvjHNnj0bf/75J0JCQnDlyhXMnj0bhw4dwtmzZ/HGG2+gd+/eqFKlCoYOHQqDwZDv60ydOhUxMTEFPipUqJBn33v37sFsNqN8+fJW+8uXL4+EhIR83zMwMBCLFy/Gpk2bsHnzZtSoUQNt2rTBoUOHxDY1a9ZEVFQUtm3bhrVr10Kr1SIsLAxXrlzJ93XtgSvciMhteHh44Pz589L7qzxwfpj0/lTyrFy5EoMGDUJQUBAUCgUaNmyIvn374vTp02KbPn36iNt16tRB48aNERwcjB07dqBHjx4Fvn5ISAi8vb3F54GBgVajOo8KCgrC9u3bxed6vR4dOnTAihUr8Nlnn8Hb2xuXLl1Cx44d8e233+Ldd9/N83X8/f3h7+//2M9fkEcTdkEQCkzia9SogRo1aojPmzVrhri4OMyePRstW7YEADRt2tRq8XRYWBgaNmyIr7/+GvPmzStSvAXhyAwREUmWnp6O9PR0lC1bVtw3ZswYpKen51r/kZiYiPT0dKuplOHDhyM9PR3ff/+9VdubN28iPT0dTz/9dJHiq1q1Kg4ePIj09HTExcXht99+g9FoRGhoaL59AgMDERwcXKjRBJVKZfVcJpPZNDU2bdo0tG/fHg0bNkR0dDR69uwJlUqFHj16IDo6Ot9+RZlmKlu2LBQKRa5RmMTExFyjNY/TtGnTAs+TXC7Hs88+y5EZIiIquTw9PXPtU6vVUKvVhWqrUqlyJQT5tS0KT09PeHp64u+//8auXbswc+bMfNvev38fcXFxCAwMtIpTyqLygly8eBFr164V15SYzWYYjUYAD9cSFfR+U6dOtboSKi/5TTOp1Wo0atQIe/bsQffu3cX9e/bsQdeuXW36DGfOnLE6T48SBAExMTGoW7euTa9rKyYzROQ2srKy8PLLLwMAtm3bBp1OZ1t/YxZeXvdP/1e3QaeyrT+VPLt27YIgCKhRowauXr2KMWPGoEaNGhg4cCCAhyNLkydPRs+ePREYGIibN29i/PjxKFu2rNUXfUhICPbt24ewsDBoNBqULl26SHEJgoAhQ4bgyy+/hJeXF4CHUzJLlizBU089hRUrVuC1117Lt39Rp5lGjRqF/v37o3HjxmjWrBkWL16MW7duYejQoWKbyMhI3LlzBytWrAAAzJ07FyEhIahduzYMBgNWrVqFTZs2Wd0XZ8qUKWjatCmqV6+O1NRUzJs3DzExMViwYIHkWAuDyQwRuQ2LxYK9e/eK2zb3FyzYe32vuE2uLyUlBZGRkbh9+zb8/PzQs2dPTJs2TRwNUigUOHfuHFasWIHk5GQEBgaidevWWL9+vdVamC+++AKjRo3CkiVLEBQUhJs3bxYprsWLF6N8+fLo0qWLuG/y5Mno27cvnnvuOXTs2BHDhw8v0nsUpE+fPrh//z6mTp2K+Ph41KlTBzt37kRwcLDYJj4+3mqqymAwYPTo0bhz5w50Oh1q166NHTt24MUXXxTbJCcnY8iQIUhISICvry8aNGiAQ4cOoUmTJg77LAAgE/57PZ0bSk1Nha+vL1JSUuDj4+PscIjyde3aNQwe/h56fjQNAcEP5/MTYm9g08wJ+H7BPFStWrXI75GRAfzzj0CkpwN2Hsl3OpPJhPXr1wN4+Mfa1rsAmywmrP/jn/51+vAuwP/Izs7GjRs3xLvFEtlLQT9btnx/8zeViNyGUqlEv379pPeXK9HvGen9icg5eDUTERERuTSnJjOHDh3CSy+9hAoVKuQq4mU0GjF27FjUrVsXnp6eqFChAt544w3cvXvXeQETUYlmNptx4sQJnDhxQnI5gxN3TuDEnRMsZ0DkQpyazGRkZKBevXp51qLIzMzE6dOn8cknn+D06dPYvHkzLl++LF6pQET0qOzsbDRp0gRNmjSRXM6gyXdN0OS7JixnQORCnLpmplOnTujUqVOex3x9fbFnzx6rfV9//TWaNGmCW7duFbp+BRE9OWQymXg1htRyBsG+0vu7Oze/XoScwF4/Uy61ADglJQUymQylSpXKt41er7cqbpaamloMkRFRSeDh4VGkS2Y9VB64OVJ6f3eVcxlzZmamzffuISpIZmYmgNx3UraVyyQz2dnZGDduHPr27VvgJVozZszAlClTijEyIiL3plAoUKpUKbHmkIeHB0euqEgEQUBmZiYSExNRqlQpKBSKIr2eSyQzRqMRr776KiwWCxYuXFhg28jISIwaNUp8npqaikqVKjk6RCIitxYQEAAABRZRJLJVTiXyoirxyYzRaETv3r1x48YN7N+//7E3ztFoNNBoNMUUHRGVJNnZ2Xj11VcBAOvWrbP5Bm/Zpmy8uvGf/r3WQavkDeJyyGQyBAYGwt/fX6wfRFQUKpWqyCMyOUp0MpOTyFy5cgUHDhxAmTJlnB0SEZVgZrMZP/74o7htc3+LGT9e+lHcptwUCoXdvoCI7MWpyUx6ejquXr0qPr9x4wZiYmLg5+eHChUqoFevXjh9+jS2b98Os9ksliv38/PLsyIrET3Z1Go1Fi9eLG7b3F+hxuIui8VtInINTk1mTp48idatW4vPc9a6DBgwAJMnT8a2bdsAAPXr17fqd+DAAbRq1aq4wiSiEiwpKcnqqsUXXngBPj4+kq6OUClUeKvRW/YMj4iKgVOTmVatWhV4jTnvaUBEBUlKSsKgIUORlmV9gztvnRZLF3+DcuXKOSkyIipOJXrNDBFRQVJTU5GWlY1W/d9BmcCKsFgsuHTqGE7833okJyfbnMxYBAsuJl0EADxd7mnIZSxfR+QKmMwQkcsrE1gRAcGhyM7MwKJxIwBAUjmDLGMW6iyqAwBIj0yHp9rTrnESkWMwmSEit+LpWwqGf+4qKkVZj7J2jIaIigOTGSJyG1oPT8zYfACbZk6Ah4eHzf091Z5IGpPkgMiIyJE4IUxEREQujckMERERuTQmM0TkNgz6bCyfPh4Xf4+BXq+3uX+2KRv9NvdDv839kG2yfQExETkH18wQkduwmM04te8nANLLGaw5twYAxDsBE1HJx2SGiNyGUqVG92Gj8fu+HZLuAKxWqPFlhy/FbSJyDUxmiMhtKFUqtO7ZDw+uXZBczmBk05H2D4yIHIprZoiIiMilcWSGiNyGxWLB/YS7yM7KhMVisb2/YMGtlFsAgMq+lVnOgMhFMJkhIrdhyM7ClH6dAUgvZxD6VSgAljMgciVMZojIrai1WpiMRsn9PVS23zmYiJyLyQwRuQ2thydm7zhWpHIGGeMzHBAZETkSJ4SJiIjIpTGZISIiIpfGZIaI3IZRr8faL6bi0h/nJJUz0Jv0eGvbW3hr21vQm2zvT0TOwTUzROQ2zGYTju3c8s+27eUMTBYTvjvzHQBgbse50EBj1/iIyDGYzBCR21AqVeg8aDjOH9oDpdL2P28qhQqftf5M3CYi18BkhojchlKtRod+byL9zg2o1bbXVlIr1JjQcoIDIiMiR+KaGSIiInJpHJkhIrchCALSkh/AYNBDEARJ/e9l3gMAlPUoC5lMZu8QicgBmMwQkdvQZ2ViQs82AICsrCyb+2caM+E/2x8AyxkQuRJOMxEREZFL48gMEbkNrYcn5u07U6RyBsIk26eniMi5ODJDRERELo3JDBEREbk0JjNE5DaMej02LZiFqxcvSC5nMPLnkRj580iWMyByIVwzQ0Ruw2w24eDmNf9sSytn8NWvXwEApr0wjeUMiFwEkxkichtKpQrt+w7Gn8ejJZczGP/8eHGbiFwDkxkichtKtRpdBo+A/n685HIG09pMc0BkRORIXDNDRERELo0jM0TkNgRBgD4rC2aTSXI5g0xjJgDAQ+XBcgZELoLJDBG5DX1WJsZ0aQ5AejkDrxleAFjOgMiVcJqJiIiIXBpHZojIbWh0Hpi1/Sh+/HIydDqdzf09VB5Ij0wXt4nINTCZISK3IZPJoNHpoFAqJa13kclknFoickFOnWY6dOgQXnrpJVSoUAEymQxbt261Oi4IAiZPnowKFSpAp9OhVatWOH/+vHOCJSIiohLJqclMRkYG6tWrh/nz5+d5fObMmZgzZw7mz5+PEydOICAgAO3atUNaWloxR0pErsBkMGD79/Nx48olGAwGm/sbzAZM2DcBE/ZNgMFse38icg6nTjN16tQJnTp1yvOYIAiYO3cuJkyYgB49egAAli9fjvLly2PNmjV4++23izNUInIBJpMRu9d8/8+2yeb+RrMR049MBwCMbzEeaoXtN94jouJXYq9munHjBhISEtC+fXtxn0ajQXh4OI4ePerEyIiopFIolAjv0RdBlUOgUChs7q+UK/H+c+/j/efeh1LOJYVErqLE/rYmJCQAAMqXL2+1v3z58oiNjc23n16vt6qWm5qa6pgAiajEUWk06Dl8DDbNnACNxvYikRqlBnM7zrV/YETkUCV2ZCbHo1ckCIJQ4FUKM2bMgK+vr/ioVKmSo0MkIiIiJyqxyUxAQACAf0dociQmJuYarfmvyMhIpKSkiI+4uDiHxklERETOVWKTmdDQUAQEBGDPnj3iPoPBgIMHD6J58+b59tNoNPDx8bF6ENGTITszA++1aYCDu3YiMzPT5v4ZhgzIpsggmyJDhiHDARESkSM4dc1Meno6rl69Kj6/ceMGYmJi4Ofnh8qVK2PkyJGYPn06qlevjurVq2P69Onw8PBA3759nRg1ERERlSROTWZOnjyJ1q1bi89HjRoFABgwYACioqLw0UcfISsrC8OGDcPff/+N5557Drt374a3t7ezQiaiEkyj88C0Tfuwff50yeUMEkcnittE5Bqcmsy0atUKgiDke1wmk2Hy5MmYPHly8QVFRC5LJpPBu5Qf1GqN5HIG5TzLOSAyInKkErtmhoiIiKgwSux9Zoio+CUlJVndm8nHxwflyrnOSIXJYMCu1d8h9tpVyeUMZv0yCwAwJmwM7wBM5CKYzBARgIeJzKAhQ5GWlS3u89ZpsXTxNy6T0JhMRuxYuuCfbWnlDD4+8DEAYGTTkUxmiFwEkxkiAvDwbtlpWdlo1f8dlAmsiPvxtxG9chFSU1NdJplRKJRo9mJ33Dh7UnI5gzcbvCluE5Fr4G8rEVkpE1gRAcGhzg5DEpVGg9c+nFikcgZLXl7igMiIyJG4AJiIiIhcGpMZIiIicmmcZiIit5GdmYHRnZvBZDRKLmfgP9sfAJA4OhGeak97h0hEDsBkhojciiE7+/GNCpBptD0JIiLnYjJDRG5DrdVh0uod+PnbWdBqtTb316l0uPH+DXGbiFwDkxkichtyuRxlAipAq/OAXG77kkC5TI6QUiH2D4yIHIoLgImIiMilcWSGiNyGyWjEgU2rcfvmDRiNRpv7G81GLDjx8A7Cw58dDpVCZe8QicgBmMwQkdswGQ3YsnA2AEhKZgxmAz7Y9QEA4K2GbzGZIXIRTGaIyG3IFQo0atMJcRfOSipnoJAr0LduX3GbiFwDkxkichtqjRYDxk+XXM5Aq9RidY/VDoiMiByJC4CJiIjIpTGZISIiIpfGaSYichvZmRmI7NEahsxMyeUMQr4KAQDcfP8myxkQuQgmM0TkVjJSkovU/17mPfsEQkTFhskMEbkNtVaHyO83Ys/SrySXM/jjnT/EbSJyDUxmiMhtyOVyBIZUhaeXt+RyBrX9azsgMiJyJC4AJiIiIpfGkRkichsmoxFHd2xGfNwtyeUMomKiAAAR9SN4B2AiF8FkhojchslowLo5nwKQXs5gyPYhAIC+dfsymSFyEUxmiMhtyBUK1G3eCnevXpRczqBrja7iNhG5BiYzROQ21Bot3vr0yyKVM9j66lb7B0ZEDsUFwEREROTSmMwQERGRS+M0ExG5DX1WJib3fREZKcnIysqyuX+mMRO1FtQCAFwYfgEeKg97h0hEDsBkhojchiAIePBXvLgtpX9sSqzk/kTkHExmiMhtqDVafLhgFfavXCh5AfBvb/4mbhORa2AyQ0RuQ65QILhmbfj4lpJ8afazQc86IDIiciRJC4Bv3Lhh7ziIiIiIJJGUzFSrVg2tW7fGqlWrkJ2dbe+YiIgkMZtMOLF3J/66ewcmk8nm/iaLCat/X43Vv6+GyWJ7fyJyDknJzNmzZ9GgQQN8+OGHCAgIwNtvv43ffvvN3rEREdnEaNBj5YwJ+PPcWRgMBpv76016vL7ldby+5XXoTXoHREhEjiApmalTpw7mzJmDO3fuYNmyZUhISMDzzz+P2rVrY86cOUhKSrJ3nEREjyWXy1Gj4XMoVaYM5HLb/7zJZXK0rdIWbau0hVzG23ARuYoi/bYqlUp0794dGzZswOeff45r165h9OjRqFixIt544w3Ex8fbK04iosdSa3UYPusb1Gv8HLRa269G0ql02NN/D/b03wOdSueACInIEYqUzJw8eRLDhg1DYGAg5syZg9GjR+PatWvYv38/7ty5g65du9orTiIiIqI8SUpm5syZg7p166J58+a4e/cuVqxYgdjYWHz22WcIDQ1FWFgYvv32W5w+fbpIwZlMJnz88ccIDQ2FTqdDlSpVMHXqVFgsliK9LhEREbkPSfeZWbRoEQYNGoSBAwciICAgzzaVK1fG999/X6TgPv/8c3zzzTdYvnw5ateujZMnT2LgwIHw9fXF+++/X6TXJiL3o8/KxPRBPZF6L1FyOYNnlzy8z8yJt06wnAGRi5CUzOzZsweVK1fOtcBOEATExcWhcuXKUKvVGDBgQJGCO3bsGLp27YrOnTsDAEJCQrB27VqcPHmySK9LRO5JEAQkxF4Xt6X0v5B0QXJ/InIOSdNMVatWxb1793Ltf/DgAUJDQ4scVI7nn38e+/btw+XLlwE8vCT8yJEjePHFF/Pto9frkZqaavUgoieDWqPFu18sQb1nn5NczuDAgAM4MOAAyxkQuRBJIzP5/YslPT1d0hUE+Rk7dixSUlJQs2ZNKBQKmM1mTJs2Da+99lq+fWbMmIEpU6bYLQYich1yhQLV6zfG77u3SC5n0Cqklf0DIyKHsimZGTVqFABAJpNh4sSJ8PD4dz7ZbDbj119/Rf369e0W3Pr167Fq1SqsWbMGtWvXRkxMDEaOHIkKFSrkO4UVGRkpxgkAqampqFSpkt1iIiIiopLFpmTmzJkzAB6OzJw7dw5qtVo8plarUa9ePYwePdpuwY0ZMwbjxo3Dq6++CgCoW7cuYmNjMWPGjHyTGY1GI2l4mYhcn9lkwu9HDuDeXwmSyxlsv7wdANDlqS5QylmLl8gV2PSbeuDAAQDAwIED8dVXX8HHx8chQeXIzMzMtchYoVDw0mwiypPRoMd3kx6OzEotZ9B9fXcAQHpkOpRqJjNErkDSb+qyZcvsHUeeXnrpJUybNg2VK1dG7dq1cebMGcyZMweDBg0qlvcnItcil8sRWrse7t+5JbmcQfNKzcVtInINhU5mevTogaioKPj4+KBHjx4Ftt28eXORAwOAr7/+Gp988gmGDRuGxMREVKhQAW+//TYmTpxol9cnIvei1urwwbwobJo5QXI5g18G/eKAyIjIkQqdzPj6+kImk4nbxcHb2xtz587F3Llzi+X9iIiIyPUUOpn579RScU0zERERET2OpDUzWVlZEARBvDQ7NjYWW7ZsQa1atdC+fXu7BkhEVFiG7CzMHtYPf8ffQXZ2ts39s4xZaBnVEgBwKOIQK2cTuQhJyUzXrl3Ro0cPDB06FMnJyWjSpAnUajXu3buHOXPm4J133rF3nEREj2WxWHDr0gVx2+b+ggUn754Ut4nINUharn/69Gm0aNECALBx40YEBAQgNjYWK1aswLx58+waIBFRYanUGrw9bR7qNGxsdR+swtIoNdj+2nZsf207NErer4rIVUgamcnMzIS3tzcAYPfu3ejRowfkcjmaNm2K2NhYuwZIRFRYCqUStZu2wJ+HfoZSafufN6Vcic5PdXZAZETkSJJGZqpVq4atW7ciLi4Ou3btEtfJJCYmOvxGekRERET/JSmZmThxIkaPHo2QkBA899xzaNasGYCHozQNGjSwa4BERIVlMZvx58njeHAvCWaz2eb+ZosZe67twZ5re2C22N6fiJxD0jRTr1698PzzzyM+Ph716tUT97dp0wbdu3e3W3BERLYw6LOxcOzDCxD0er3N/bNN2Wi/6uFIc3pkOjzVnnaNj4gcQ3LhkYCAAAQEBFjta9KkSZEDIqKiS0pKQmpqqtU+Hx8feHiUc1JExUMulyOo6lNIToyXXM6gXvl64jYRuQZJyUxGRgb+97//Yd++fUhMTMx1CeT169ftEhwR2S4pKQmDhgxFWpb1fVa8dVp8/eU3ANw3oVFrdRi7eH2RyhnEDI2xf2BE5FCSkpk333wTBw8eRP/+/REYGCiWOSAi50tNTUVaVjZa9X8HZQIrAgDux99G9MpFSEtLgzsnM0T0ZJKUzPz000/YsWMHwsLC7B0PEdlJmcCKCAgOdXYYREQOJymZKV26NPz8/OwdCxFRkRiyszBv1JtIunVDcjmDTqs7AQB+6vcTyxkQuQhJK9w+/fRTTJw4EZmZmfaOh4hIMovFgqtnTyHl7weSyxkcjD2Ig7EHWc6AyIVIGpn54osvcO3aNZQvXx4hISFQqVRWx0+fPm2X4IiIbKFSazBw4kz8+uNayeUMNvTaIG4TkWuQlMx069bNzmEQkat49LJvHx8flCtXMhYVK5RKNAhvh+u/RksuZ/BK7VccEBkROZKkZGbSpEn2joOIXEBel31767RYuvibEpPQENGTR/JN85KTk7Fx40Zcu3YNY8aMgZ+fH06fPo3y5csjKCjInjESUQnx6GXfOZd8p6amlohkxmI24/ofMUj5+4HkcgbHbx8HADSt2BQKucLeIRKRA0hKZn7//Xe0bdsWvr6+uHnzJt566y34+flhy5YtiI2NxYoVK+wdJxGVICX1sm+DPhtz3x8IQHo5g+eXPQ+A5QyIXImkq5lGjRqFiIgIXLlyxeoum506dcKhQ4fsFhwRkS1kMhnKBVWCzsND0s08ZTIZqvlVQzW/arwZKJELkTQyc+LECXz77be59gcFBSEhIaHIQRERSaHReeCTFduwaeYE6HS23yPGQ+WBK+9ecUBkRORIkkZmtFptriJ2AHDp0qUSMW9ORERETw5JyUzXrl0xdepUGI1GAA+HZm/duoVx48ahZ8+edg2QiIiIqCCSkpnZs2cjKSkJ/v7+yMrKQnh4OKpVqwZvb29MmzbN3jESERWKQZ+Nb8a/i3OnTkheANx5TWd0XtMZ2SbbyyEQkXNIWjPj4+ODI0eO4MCBAzh16hQsFgsaNmyItm3b2js+IqJCs5jNuPDrEQCQfGn2zis7xW0icg02JzMWiwVRUVHYvHkzbt68CZlMhtDQUAQEBEAQBF4BQEROo1Sp0W/MFJz8aVOuMiuFoVaosazrMnGbiFyDTcmMIAh4+eWXsXPnTtSrVw9169aFIAi4ePEiIiIisHnzZmzdutVBoRIRFUypUuG5ji/j9u+/SkpmVAoVIupH2D8wInIom5KZqKgoHDp0CPv27UPr1q2tju3fvx/dunXDihUr8MYbb9g1SCIiIqL82LQAeO3atRg/fnyuRAYAXnjhBYwbNw6rV6+2W3BERLawmM24ffUS0lNTJa+ZiUmIQUxCDNfMELkQm5KZ33//HR07dsz3eKdOnXD27NkiB0VEJIVBn42Zb7+KU8eOSL6aqcG3DdDg2wa8monIhdg0zfTgwQOUL18+3+Ply5fH33//XeSgiIikkMlk8C1TDlnpqZLLGVTwriBuE5FrsCmZMZvNUCrz76JQKGAymYocFBGRFBqdBz7dsLtI5QzujLrjgMiIyJFsvpopIiICGo0mz+NShnWJiIiIisKmZGbAgAGPbcMrmYiIiKg42ZTMLFu2zFFxEBEVmUGfjaVTxuD2pT8kLwDuv6U/AGBl95XQKrX2DpGIHEBSOQMiopLIYjYj5tBeANLLGWy8sBEAENU1yp6hEZEDMZkhIrehVKnR691xiNm7TXI5g/md5ovbROQamMwQkdtQqlRo2a0Pki7/LrmcwfAmwx0QGRE5kk03zXOGO3fu4PXXX0eZMmXg4eGB+vXr49SpU84Oi4iIiEqIEj0y8/fffyMsLAytW7fGTz/9BH9/f1y7dg2lSpVydmhEVAJZLBYk3o5FZkYGLBaL7f0FC649uAYAqOpXFXJZif/3HhGhhCczn3/+OSpVqmR1FVVISIjzAiKiEs2QnYXPBnQDAGRn216OIMuYhafmPwUASI9Mh6fa057hEZGDlOh/dmzbtg2NGzfGK6+8An9/fzRo0ABLlixxdlhEVILpPL2gKOBO5Y/jq/GFr8bXjhERkaOV6GTm+vXrWLRoEapXr45du3Zh6NCheO+997BixYp8++j1eqSmplo9iOjJoPXwxOfbDuP5Nu3h4eFhc39PtSeSxyUjeVwyR2WIXEiJnmayWCxo3Lgxpk+fDgBo0KABzp8/j0WLFuV7p+EZM2ZgypQpxRkmEREROVGJHpkJDAxErVq1rPY9/fTTuHXrVr59IiMjkZKSIj7i4uIcHSYRERE5UYkemQkLC8OlS5es9l2+fBnBwcH59tFoNPkWwiQi92bU67Hq84mI/eOspHIGepMeb29/GwDwbZdvoVHybwmRKyjRIzMffPABjh8/junTp+Pq1atYs2YNFi9ejOHDeVMrIsrNbDbht93/h7/u3pFUzsBkMWH52eVYfnY5TBaTAyIkIkco0SMzzz77LLZs2YLIyEhMnToVoaGhmDt3Lvr16+fs0IioBFIqVeg6ZCTORf8MpYQrmlQKFWa2nSluE5FrKNHJDAB06dIFXbp0cXYYROQClGo12vQZgOTYy1Crba+tpFaoMSZsjAMiIyJHKtHTTERERESPU+JHZojI9SQlJVnd48nHxwflypVz+PtaLBYkJyVCn50tuZxBfFo8ACDQO5DlDIhcBJMZIrKrpKQkDBoyFGlZ/5YT8NZpsXTxNw5PaAzZWZj4agcA0ssZVPyyIgCWMyByJUxmiMiuUlNTkZaVjVb930GZwIq4H38b0SsXITU1tVhGZ+QKJQSL7Vcy5VDK+WeRyNXwt5aIHKJMYEUEBIcW63tqPTwxd/cJbJo5QXI5A+MnRgdERkSOxAlhIiIicmlMZoiIiMilMZkhIrdh1Oux4asZuHLhD8nlDIbvGI7hO4ZDb7K9PxE5B9fMEJHbMJtNOLJtwz/b0soZLDy5EAAws91MaMDaTESugMkMEbkNpVKFjm+8jYu/7JNczmBS+CRxm4hcA5MZInIbSrUaLw4Yiqy/4iSXM5jcarL9AyMih+KaGSIiInJpHJkhIrchCAIy09NgMhohCIKk/in6FACAr8YXMpnM3iESkQMwmSEit6HPysS4ri0BAFlZWTb3zzRmovTnpQGwnAGRK+E0ExEREbk0jswQkdvQ6Dzw5a7fsHn2ROh0Opv7e6g8YPjYAIA1mohcCX9bichtyGQyKJQqyOVySetdZDIZL8kmckGcZiIiIiKXxmSGiNyGyWDA1m+/xLVLF2EwGGzubzAbMGb3GIzZPQYGs+39icg5OM1ERG7DZDJi/4YV/2ybbO5vNBsx+9hsAMDkVpOhVth+4z0iKn5MZojIbSiVKrzQ+w1c/u2w5HIGo5uNFreJyDUwmSEit6FUq9Ht7Q+wKeWe5HIGs9rPckBkRORITGaIJEhKSkJqaqr43MfHB+XKlXNiRERETy4mM0Q2SkpKwqAhQ5GWlS3u89ZpsXTxN0xonEwQBJhNRlgsFsnlDEyWh2ttlHIlyxkQuQgmM0Q2Sk1NRVpWNlr1fwdlAivifvxtRK9chNTUVCYzTqbPysQHHZoAkF7OwGuGFwCWMyByJUxmiCQqE1gRAcGhzg6DiOiJx2SGiNyGRueB//14CP/31aeSyxn8PfZvcZuIXAOTGSJyGzKZDB5e3lCqVJLLGZTSlrJ/YETkULwDMBEREbk0jswQkdswGQzYufwb3Lx6WXI5g+mHpwMAxrcYzzsAE7kIJjP0RHv0fjGA/e4Zw3vRFD+TyYifV3z7z7a0cgZTDk4BAIxpPobJDJGLYDJDT6y87hcD2OeeMcV9L5r/Jk6xsbGSvsjdgUKhxPMv98b1M8ehUChs7q+UKzGs8TBxm4hcA39b6Yn16P1iANjtnjHFeS+aRxOnrMwM3E34C0bjk1f1WaXRoPf7kdg0cwI0Go3N/TVKDRZ0XuCAyIjIkZjM0BPPkfeLKY570TyaOF2JOYFNC2fDbDY79H2JiEoKXs1E5CZyEqdS/gHODoWIqFhxZIaI3EZ2ZgZGtn8WgsWMzMxMm/tnGDJQ6vNSAIDkscksZ0DkIpjMEJFbsZiLtvg5p9AkEbkOJjNE5DbUWh2mrtuFnYs+h1artbm/TqXD7Q9ui9tE5BqYzBCR25DL5ShVzh8arRZyue1LAuUyOYJ8ghwQGRE5kkstAJ4xYwZkMhlGjhzp7FCIiIiohHCZkZkTJ05g8eLFeOaZZ5wdChGVUCaDAfvWL0fcjeuSyxl8dfwrAMD7Td/nHYCJXIRLjMykp6ejX79+WLJkCUqXLu3scIiohDKZjPhx8Vxcv/yn5HIGH+39CB/t/QhGs9EBERKRI7hEMjN8+HB07twZbdu2fWxbvV6P1NRUqwcRPRkUCiWatH8J5SsESS5nMKDeAAyoN4DlDIhcSIn/bV23bh1Onz6NEydOFKr9jBkzMGXKFAdHRUQlkUqjwetjpxapnEFUtyj7B0ZEDlWiR2bi4uLw/vvvY9WqVYW+zDIyMhIpKSniIy4uzsFREhERkTOV6JGZU6dOITExEY0aNRL3mc1mHDp0CPPnz4der881lKzRaCT9i4yIiIhcU4lOZtq0aYNz585Z7Rs4cCBq1qyJsWPHSpoTJyL3lZ2ZgbEvt4BBny25nEHQnIf3mbkz6g7LGRC5iBKdzHh7e6NOnTpW+zw9PVGmTJlc+4mIACArI71I/VP0KXaKhIiKS4lOZoiIbKHW6vDx8q3YteRLyeUMLo+4LG4TkWtwuWQmOjra2SEQUQkll8vhXzEYHp6ekssZVC9T3QGREZEjuVwyQ0TFx2DQIzY2VnweGxsr6WZ0RESOxGSGiPKUlvwAN65dx4RPp4tXCGZlZuBuwl8wGm0vFVAcTEYjDm1djzu3bsJotP0OvkazEYtPLQYADGk0BCqFyt4hEpEDMJkhojxlZ2ZArlIhvP87CAqpCgC4EnMCmxbOhtlsdnJ0eTMZDdj49f8AQFIyYzAbMOKnEQCAiPoRTGaIXASTGSIqUJmACggIDgUAJN0t2TehlCsUqN+yLW5f+kPSrRsUcgV61eolbhORa2AyQ0RuQ63RYtCkWZLLGWiVWvzwyg8OiIyIHKlElzMgIiIiehwmM0REROTSOM1ERA736CXeAODj44Ny5crZ9X30WZn4pHd7ZKWnIisry+b+mcZMVP/64X1mrrx7BR4qD7vGR0SOwWSGiBwqr0u8AcBbp8XSxd/YNaERBAEp95PEbSn976bdldyfiJyDyQwROVRel3jfj7+N6JWLkJqaatdkRq3R4qNv12Ff1HzJC4DPvH1G3CYi18BkhoiKxX8v8XYUuUKBitVqwMvHR/Kl2fUD6ts/MCJyKC4AJiIiIpfGkRkichsmoxG//rwNCXduSy5nsPrcagBAv7r9eAdgIhfBZIaI3IbJaMDqWZMASC9nMPDHgQCAV2q9wmSGyEUwmSEityFXKFDrueeRcO2S5DUzL1Z/UdwmItfAZIaI3IZao8XQ6V8XqZzBjr47HBAZETkSFwATERGRS2MyQ0RERC6N00xE5Db0WZn49I2Xkf73fcnlDOp9Uw8AcHboWZYzIHIRTGaIyG0IgoCkO3HitpT+Vx9cldyfiJyDyQwRuQ21RouRXy1D9OpvJS8APjLwiLhNRK6ByQwRuQ25QoEqderjTGk/yZdmh1UOc0BkRORIXABMRERELo0jM0TkNswmE84c3IOkhHiYTCab+5ssJmy5uAUA0P3p7lDK+SeSyBXwN5WI3IbRoMeyqR8BAAwGg8399SY9em/sDQBIj0yHUs0/kUSugL+pROQ25HI5qtVrhKRbNyCX2z6LLpfJER4cLm4TkWtgMkNEbkOt1eG9Od9h08wJ0GptvxpJp9IhOiLa/oERkUPxnx5ETwiDQY9bt26Jz5OSkpwYDRGR/TCZIXoCpCU/wI1r1zHl89nivnfefZ8JDRG5BSYzRE+A7MwMyFUqPP/am+K+9KxspKamOjEq+zNkZ+HzIX1w8uhhZGdn29w/y5iF+t/UR/1v6iPLaHs5BCJyDq6ZIXqClCkf6OwQHMpiseDOtcvits39BQvO/nVW3CYi18BkhojchlqjxbDPF+HwhqWSyxnsfn23uE1EroHJDBG5DblCgZqNm+L8/v+TXM6gXdV2DoiMiByJa2aIiIjIpXFkhojchtlkwvnjh3E/KVFyOYNdV3cBADpU68ByBkQugr+pROQ2jAY9vp3wHgDp5Qy6rO0CgOUMiFwJf1OJyG3I5XJUrlELf8ffkVzOoHGFxuI2EbkGJjNE5DbUWh1GL1xdpHIGJ9464YDIiMiRSvQ/PWbMmIFnn30W3t7e8Pf3R7du3XDp0iVnh0VEREQlSIlOZg4ePIjhw4fj+PHj2LNnD0wmE9q3b4+MjAxnh0ZERWQw6BEbG4tr166JD5ZXICIpSvQ0088//2z1fNmyZfD398epU6fQsmVLJ0VFREWVUytqwqfTrW5u563TYunib1CuXDlJr2vIzsKX70Xg/p1bkssZtF3ZFgCwt/9e6FQ6SXEQUfEq0cnMo1JSUgAAfn5++bbR6/XQ6/Xic3erPUPkDnJqRYX3fwdBIVUBAPfjbyN65SKkpqZKTmYsFgtunD8rbtvcX7DgaNxRcZuIXIPLJDOCIGDUqFF4/vnnUadOnXzbzZgxA1OmTCnGyIhIqjIBFRAQHGq311OpNXhzyhwc27IKarXa5v4apQZb+mwRt4nINZToNTP/NWLECPz+++9Yu3Ztge0iIyORkpIiPuLi4oopQiJyNoVSiWeeb42y5QOgVNr+bzWlXIluNbuhW81uvGEekQtxid/Wd999F9u2bcOhQ4dQsWLFAttqNBpJBeaIiIjINZXoZEYQBLz77rvYsmULoqOjERpqv+FoInI/FrMZV2JOIvnBfZjNZpv7my1mHL51GADQonILKOS2F6skouJXopOZ4cOHY82aNfjxxx/h7e2NhIQEAICvry90Ol5lQETWDPpsfP3hWwBgdSFAYWWbstF6eWsAD8sZeKo97RofETlGiU5mFi1aBABo1aqV1f5ly5YhIiKi+AMiohJNJpMhILgKUu8lQiaTSepfq1wtcZuIXEOJTmYEQXB2CETkQjQ6D4xfugmbZk6QNHrrofLA+WHnHRAZETmSy1zNRERERJSXEj0yQ0S5JSUlWd0MMjY2FiaTyYkRERE5F5MZoscoSclDUlISBg0ZirSsf2/Vn5WZgbsJf8FoNDglppLEkJ2FBWOG4q/Yq5LLGby87mUAwLZXt7GcAZGLYDJDLuHRhMLHx0fyLe9tfd+SlDykpqYiLSsbrfq/gzKBD++5dCXmBDYtnC3pUmR3Y7FYcOn0r+K2zf0FC/Ze3ytuE5FrYDJDJV5eCUVRCxIWVklNHsoEVhTLACTd5V2uc6jUGvSPnIYT2zdILmewqvsqcZuIXAOTGSrxHk0o7FGQ0FZMHlyDQqnEs21fxK3Tv0guZ9DvmX4OiIyIHInJDLmM/yYUREREOZjMEJHbsJjNiP3zPFJTkiWXMzgdfxoA0DCwIcsZELkIJjNE5DYM+mx8Mfx1ANLLGTT5rgkAljMgciVMZojIbchkMviVD0RGSrLkcgbBvsHidmE460o7IvoXkxkichsanQcmr9lZpHIGN0feLHR7Z15pR0T/YjJDRCRRSbjSjoiYzJAb4XA/OQuvtCNyLiYz5BY43E/AwwXASz75AHevXpS8APjVja8CANb1WgetUmvvEInIAZjMkFvgcD8BDy/NPnc0GgAkX5r946UfxW0icg1MZsitcLj/yaZUqfHqqE9w+uctUKlUNvdXK9RY3GWxuE1EroHJDBG5DaVKheadeyD+/ClJyYxKocJbjd4Sn3MdFpFrYDJDRJQHrsMich1MZojIbVgsFsTfvIaM9DRYLBbb+wsWXEy6CABQp6odtg7r0REfgKM+REXBZIaI3IYhOwszBvcCAGRnZz+mdW5ZxizUWVQHAPD7q78DsP86rLxGfACO+hAVBZMZInIrnr6lYMjMlNy/rEdZO0aT26NX3gHg1XdERcRkhojchtbDEzM2H8CmmRPg4eFhc39PtSeSxiQBAK5du2bv8Kzwyjsi+5E7OwAiIiKiomAyQ0RERC6NyQwRuQ2DPhvLp4/Hxd9jJJcz6Le5H/pt7ge92fb+ROQcXDNDRG7DYjbj1L6fAEgvZ7Dm3BoAwLja4+waGxE5DpMZcijeQZWKk1KlRvdho/H7vh2Syxl82eFLAIBKbnt/InIOJjPkMLyDKhU3pUqF1j374cG1C5LLGYxsOhKA469mIiL7YTJDDsNK1uRKHh1FjI2NhclkcmJERFRYTGbI4Xg/DSouFosF9xPuIjsr06ZyBjmjiKlZWdBrsh6+1t8WxCckwmg0OCpcIrITJjNFxDUhRCWHITsLU/p1BmBbOYOcUcSwfoMw4/orAIChXl9j26KvJS0kLklYB4qeBExmioBrQogAg0GP2NhY8bmzp2fUWi1MRqOkvn4BQdDEPrxzsG+58vYMyylYB4qeFExmioBrQuhJl5b8ADeuXceET6dDo9EAALIyM3A34S+nTM9oPTwxe8cxyeUMNAodVr52FwBw7tghe4dX7FgHip4UTGbsgGtC6EmVnZkBuUqF8P7vICikKgDgSswJbFo4u8RPz/x3+sXZo0mOxr9R5O6YzBBRkZUJqCB+WSbdjXNyNI/36PSLM0eTiKjomMwQFZNH15YAXIhpb0a9Hmu/mIobf5wrsJzBo9MvOaNJemMWvjn+HgDgOaFrcYWdJy7cJSo8JjMkGa/kKry81pYAXIhpb2azCcd2bvln+/HTXDnTLzmjSRbBjP1XVwAAng3t4rhAH4MLd4lsw2SGJHGFK7lK0khIXmtLuBDT/pRKFToPGo7zh/ZAqbT9z5tcpsSr9T4GACjSFPYOr9C4cJfINi6RzCxcuBCzZs1CfHw8ateujblz56JFixbODuuJVtKv5CrKSMh/kyB7Lwz979oSyu3RBNTW5FOpVqNDvzeRfucG1Gq1ze+vlKvQo+5oACXjaiYu3CUqnBKfzKxfvx4jR47EwoULERYWhm+//RadOnXChQsXULlyZWeH98Szxx9bR0xXSR0JeTQJ4sLQ4pNXAlrSRvsKoySNCBI9KUp8MjNnzhwMHjwYb775JgBg7ty52LVrFxYtWoQZM2Y4OTr3VVzrYRw9XWXrSMijSVBhLzMuaTeOc0WPnnspo32CICAt+QEMBj0EQbA5BkEQkJp9T9y2FddGScP1d1RUJTqZMRgMOHXqFMaNG2e1v3379jh69KiTonI/j/4huX//Pj6Z8in05n9r2zjqj7HU6SpHJw85SVBhLjN29I3jHDntVRIVZSpOn5WJCT3bAACysrLE/YUtImm0ZOPNjdUAAGNDN+Q6/rifu6KsjSrM/+eiTsPZmz2SEEf+g4ZXhDlGSUw+S3Qyc+/ePZjNZpQvb31b8fLlyyMhISHPPnq93uqSzJSUFADI9QNtD2lpaTCZjLh77TKyMtLxd8JdZGVm4sKFC0hLS7P7+znCgwcPMP3zWcj+z8hDdmYm4v9KRMc33oaffwBSH9xDzK6tOH78OCpVqgQAiIuLgz47u8DPbksbfWYmsjLSH/73Ma9z+8pFXLtyFWMnTYVGo7aKOfbyBWRlpCPx1g1YLGbcvXEVwj+f7dH3f/R1AeTql9frPLrv1p9/AAo5arbsgLIBFR7GfOVP3Nq6FnFXL8FkMEiO59HP+ujntDnmm9cAPA0AyMoq+DwX5rPbq01e+wrz+/RozIb/1GP6888/YTabC/wZz/XzcvMa8M9LJMXdtIrHlp87fVam+P/n0Z9pqf+f83p/jVyOCeM+gp+fX6HOT14/d1LldV4fF09+Md77OxnPtHsZPn5l8/x7Y6/4pMZI/8rrvHpptVg4by7Kli1r1/fK+d4u1CipUILduXNHACAcPXrUav9nn30m1KhRI88+kyZNEgDwwQcffPDBBx9u8IiLi3tsvlCiR2bKli0LhUKRaxQmMTEx12hNjsjISIwaNUp8brFY8ODBA5QpUwYymcyu8aWmpqJSpUqIi4uDj4+PXV+b/sXzXDx4nosHz3Px4HkuHo48z4IgIC0tDRUqVHhs2xKdzKjVajRq1Ah79uxB9+7dxf179uxB165d8+yj0WisFt4BQKlSpRwZJnx8fPjLUgx4nosHz3Px4HkuHjzPxcNR59nX17dQ7Up0MgMAo0aNQv/+/dG4cWM0a9YMixcvxq1btzB06FBnh0ZEREQlQIlPZvr06YP79+9j6tSpiI+PR506dbBz504EBwc7OzQiIiIqAUp8MgMAw4YNw7Bhw5wdRi4ajQaTJk3KNa1F9sXzXDx4nosHz3Px4HkuHiXlPMsEQcKdoYiIiIhKCLmzAyAiIiIqCiYzRERE5NKYzBAREZFLYzJDRERELo3JTAEWLlyI0NBQaLVaNGrUCIcPHy6w/cGDB9GoUSNotVpUqVIF33zzTTFF6vpsOdebN29Gu3btUK5cOfj4+KBZs2bYtWtXMUbrumz9mc7xyy+/QKlUon79+o4N0E3Yep71ej0mTJiA4OBgaDQaVK1aFUuXLi2maF2Xred59erVqFevHjw8PBAYGIiBAwfi/v37xRStazp06BBeeuklVKhQATKZDFu3bn1sH6d8Fxa9gpJ7WrdunaBSqYQlS5YIFy5cEN5//33B09NTiI2NzbP99evXBQ8PD+H9998XLly4ICxZskRQqVTCxo0bizly12PruX7//feFzz//XPjtt9+Ey5cvC5GRkYJKpRJOnz5dzJG7FlvPc47k5GShSpUqQvv27YV69eoVT7AuTMp5fvnll4XnnntO2LNnj3Djxg3h119/FX755ZdijNr12HqeDx8+LMjlcuGrr74Srl+/Lhw+fFioXbu20K1bt2KO3LXs3LlTmDBhgrBp0yYBgLBly5YC2zvru5DJTD6aNGkiDB061GpfzZo1hXHjxuXZ/qOPPhJq1qxpte/tt98WmjZt6rAY3YWt5zovtWrVEqZMmWLv0NyK1PPcp08f4eOPPxYmTZrEZKYQbD3PP/30k+Dr6yvcv3+/OMJzG7ae51mzZglVqlSx2jdv3jyhYsWKDovR3RQmmXHWdyGnmfJgMBhw6tQptG/f3mp/+/btcfTo0Tz7HDt2LFf7Dh064OTJkzAajQ6L1dVJOdePslgsSEtLg5+fnyNCdAtSz/OyZctw7do1TJo0ydEhugUp53nbtm1o3LgxZs6ciaCgIDz11FMYPXo0srKyiiNklyTlPDdv3hy3b9/Gzp07IQgC/vrrL2zcuBGdO3cujpCfGM76LnSJOwAXt3v37sFsNueqzF2+fPlcFbxzJCQk5NneZDLh3r17CAwMdFi8rkzKuX7UF198gYyMDPTu3dsRIboFKef5ypUrGDduHA4fPgylkn8qCkPKeb5+/TqOHDkCrVaLLVu24N69exg2bBgePHjAdTP5kHKemzdvjtWrV6NPnz7Izs6GyWTCyy+/jK+//ro4Qn5iOOu7kCMzBZDJZFbPBUHIte9x7fPaT7nZeq5zrF27FpMnT8b69evh7+/vqPDcRmHPs9lsRt++fTFlyhQ89dRTxRWe27Dl59lisUAmk2H16tVo0qQJXnzxRcyZMwdRUVEcnXkMW87zhQsX8N5772HixIk4deoUfv75Z9y4cYNFix3AGd+F/OdWHsqWLQuFQpErw09MTMyVceYICAjIs71SqUSZMmUcFqurk3Kuc6xfvx6DBw/GDz/8gLZt2zoyTJdn63lOS0vDyZMncebMGYwYMQLAwy9dQRCgVCqxe/duvPDCC8USuyuR8vMcGBiIoKAg+Pr6ivuefvppCIKA27dvo3r16g6N2RVJOc8zZsxAWFgYxowZAwB45pln4OnpiRYtWuCzzz7j6LmdOOu7kCMzeVCr1WjUqBH27NljtX/Pnj1o3rx5nn2aNWuWq/3u3bvRuHFjqFQqh8Xq6qSca+DhiExERATWrFnDOe9CsPU8+/j44Ny5c4iJiREfQ4cORY0aNRATE4PnnnuuuEJ3KVJ+nsPCwnD37l2kp6eL+y5fvgy5XI6KFSs6NF5XJeU8Z2ZmQi63/spTKBQA/h05oKJz2nehQ5cXu7Ccy/6+//574cKFC8LIkSMFT09P4ebNm4IgCMK4ceOE/v37i+1zLkf74IMPhAsXLgjff/89L80uJFvP9Zo1awSlUiksWLBAiI+PFx/JycnO+gguwdbz/ChezVQ4tp7ntLQ0oWLFikKvXr2E8+fPCwcPHhSqV68uvPnmm876CC7B1vO8bNkyQalUCgsXLhSuXbsmHDlyRGjcuLHQpEkTZ30El5CWliacOXNGOHPmjABAmDNnjnDmzBnxEviS8l3IZKYACxYsEIKDgwW1Wi00bNhQOHjwoHhswIABQnh4uFX76OhooUGDBoJarRZCQkKERYsWFXPErsuWcx0eHi4AyPUYMGBA8QfuYmz9mf4vJjOFZ+t5vnjxotC2bVtBp9MJFStWFEaNGiVkZmYWc9Sux9bzPG/ePKFWrVqCTqcTAgMDhX79+gm3b98u5qhdy4EDBwr8e1tSvgtlgsDxNSIiInJdXDNDRERELo3JDBEREbk0JjNERETk0pjMEBERkUtjMkNEREQujckMERERuTQmM0REROTSmMwQkUuSyWTYunWrU9775s2bkMlkiImJccr7E5E1JjNEVKCXXnop30Kex44dg0wmw+nTp4s5qseLiIiATCaDTCaDUqlE5cqV8c477+Dvv/+2+XW6detmta9SpUqIj49HnTp17BgxEUnFZIaICjR48GDs378fsbGxuY4tXboU9evXR8OGDZ0Q2eN17NgR8fHxuHnzJr777jv83//9H4YNG1bk11UoFAgICIBSqbRDlERUVExmiKhAXbp0gb+/P6Kioqz2Z2ZmYv369Rg8eDAAYNOmTahduzY0Gg1CQkLwxRdfiG2//vpr1K1bV3y+detWyGQyLFiwQNzXoUMHREZGis//7//+D40aNYJWq0WVKlUwZcoUmEwmm2LXaDQICAhAxYoV0b59e/Tp0we7d+8Wj5vNZgwePBihoaHQ6XSoUaMGvvrqK/H45MmTsXz5cvz444/iKE90dHSe00wHDx5EkyZNoNFoEBgYiHHjxtkcLxFJw2SGiAqkVCrxxhtvICoqCv8t5fbDDz/AYDCgX79+OHXqFHr37o1XX30V586dw+TJk/HJJ5+ICVCrVq1w/vx53Lt3D8DDL/6yZcvi4MGDAACTyYSjR48iPDwcALBr1y68/vrreO+993DhwgV8++23iIqKwrRp0yR/juvXr+Pnn3+GSqUS91ksFlSsWBEbNmzAhQsXMHHiRIwfPx4bNmwAAIwePRq9e/cWR3ji4+PRvHnzXK99584dvPjii3j22Wdx9uxZLFq0CN9//z0+++wzyfESkQ0cXsqSiFzexYsXBQDC/v37xX0tW7YUXnvtNUEQBKFv375Cu3btrPqMGTNGqFWrliAIgmCxWISyZcsKGzduFARBEOrXry/MmDFD8Pf3FwRBEI4ePSoolUohLS1NEARBaNGihTB9+nSr11u5cqUQGBgoPgcgbNmyJd+YBwwYICgUCsHT01PQarVitd85c+YU+FmHDRsm9OzZ0+p1unbtatXmxo0bAgDhzJkzgiAIwvjx44UaNWoIFotFbLNgwQLBy8tLMJvNBb4fERUdR2aI6LFq1qyJ5s2bY+nSpQCAa9eu4fDhwxg0aBAA4OLFiwgLC7PqExYWhitXrsBsNkMmk6Fly5aIjo5GcnIyzp8/j6FDh8JsNuPixYuIjo5Gw4YN4eXlBQA4deoUpk6dCi8vL/Hx1ltvIT4+HpmZmYWOu3Xr1oiJicGvv/6Kd999Fx06dMC7775r1eabb75B48aNUa5cOXh5eWHJkiW4deuWTefn4sWLaNasGWQymdXnT09Px+3bt216LSKyHZMZIiqUwYMHY9OmTUhNTcWyZcsQHByMNm3aAAAEQbD6Is/Z91+tWrVCdHQ0Dh8+jHr16qFUqVJo2bIlDh48iOjoaLRq1Upsa7FYMGXKFMTExIiPc+fO4cqVK9BqtYWO2dPTE9WqVcMzzzyDefPmQa/XY8qUKeLxDRs24IMPPsCgQYOwe/duxMTEYODAgTAYDDadm4I+/6P7icj+mMwQUaH07t0bCoUCa9aswfLlyzFw4EDxi7pWrVo4cuSIVfujR4/iqaeegkKhAPDvupmNGzeKiUt4eDj27t1rtV4GABo2bIhLly6hWrVquR5yufQ/W5MmTcLs2bNx9+5dAMDhw4fRvHlzDBs2DA0aNEC1atVw7do1qz5qtRpms7nA161VqxaOHj1qlcAdPXoU3t7eCAoKkhwvERUOkxkiKhQvLy/06dMH48ePx927dxERESEe+/DDD7Fv3z58+umnuHz5MpYvX4758+dj9OjRYps6deqgTJkyWL16tZjMtGrVClu3bkVWVhaef/55se3EiROxYsUKTJ48GefPn8fFixexfv16fPzxx0X6DK1atULt2rUxffp0AEC1atVw8uRJ7Nq1C5cvX8Ynn3yCEydOWPUJCQnB77//jkuXLuHevXswGo25XnfYsGGIi4vDu+++iz///BM//vgjJk2ahFGjRhUp+SKiQnLqih0icilHjx4VAAjt27fPdWzjxo1CrVq1BJVKJVSuXFmYNWtWrjY9e/YUFAqFkJKSIgjCw4XBfn5+QuPGjXO1/fnnn4XmzZsLOp1O8PHxEZo0aSIsXrxYPI5CLAB+dOGuIAjC6tWrBbVaLdy6dUvIzs4WIiIiBF9fX6FUqVLCO++8I4wbN06oV6+e2D4xMVFo166d4OXlJQAQDhw4kGsBsCAIQnR0tPDss88KarVaCAgIEMaOHSsYjcZ84yMi+5EJwiMT20REREQuhOOfRERE5NKYzBAREZFLYzJDRERELo3JDBEREbk0JjNERETk0pjMEBERkUtjMkNEREQujckMERERuTQmM0REROTSmMwQERGRS2MyQ0RERC6NyQwRERG5tP8HW8brdh8eOA4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vowels = set(\"aeiou\")\n",
    "vowel_ratios = [sum(ch in vowels for ch in w)/len(w) for w in words if len(w) > 2]\n",
    "mean, median = np.mean(vowel_ratios), np.median(vowel_ratios)\n",
    "p95, p99 = np.percentile(vowel_ratios, [95, 99])\n",
    "print(f\"Mean: {mean:.3f}\")\n",
    "print(f\"Median: {median:.3f}\")\n",
    "print(f\"95th: {p95:.3f}\")\n",
    "print(f\"99th: {p99:.3f}\")\n",
    "plt.hist(vowel_ratios, bins=100, density=True, alpha=0.7, color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.axvline(mean, color=\"blue\", linestyle=\"-\", label=f\"Mean = {mean:.2f}\")\n",
    "plt.axvline(p95, color=\"green\", linestyle=\":\", label=f\"95th % = {p95:.2f}\")\n",
    "plt.axvline(0.51, color=\"black\", linestyle=\":\", label=f\"95th % = {p95:.2f}\")\n",
    "plt.xlabel(\"Vowel Ratio\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Vowel Ratio Distribution\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df98489-9347-4827-b80f-1daf248238f7",
   "metadata": {},
   "source": [
    "Analysis of vowel ratios shows that English words average around 0.39 vowels per letter (median 0.385), with only 5% of words exceeding 0.55 and 1% exceeding 0.60, indicating that vowel-heavy words are rare outliers. To reflect this, we introduce a cutoff at 0.51, marking the final spike in the plot, marking the point where vowel density becomes statistically unusual. This threshold is later used in the solver (e.g., skipping further vowel guesses when a candidate exceeds 0.51) to prevent overcommitting to unrealistic word structures and to maintain a balanced exploration of vowels and consonants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b9f42e-451d-456e-8a8e-b22a167b1f86",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8815d45f-24c2-4cd4-a4e7-4965ce36ec8b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5c1f9a-bfe5-4716-8f88-a176578ce67d",
   "metadata": {},
   "source": [
    "This code builds three probability models from the word list: positional probabilities (likelihood of a letter at each position for words of a given length), bigram probabilities (likelihood of one letter following another), and global frequencies of letters. Using these, the guess_next_letter function scores unguessed letters in candidate words matching the current mask, combining weighted contributions from positional, global, and bigram models. If no candidates fit, it falls back to global letter frequencies. The results are returned as ranked guesses, with an option to normalize scores into probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65d79bac-f94c-4c12-9597-16b35078cb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10: [('l', 1.0777875321605608), ('c', 0.7019792177239896), ('p', 0.5785837994494074), ('k', 0.32570261238010006), ('f', 0.19501921763785035), ('y', 0.1833249455205664), ('t', 0.18268168438313523), ('n', 0.13659730628699743)]\n",
      "Normalized: [('l', 0.3187139843062195), ('c', 0.20758320791898544), ('p', 0.17109378469789197), ('k', 0.09631395260484575), ('f', 0.057669392171426234), ('y', 0.054211263413349774), ('t', 0.05402104380703362), ('n', 0.04039337108024772)]\n"
     ]
    }
   ],
   "source": [
    "alphabet = set(\"\".join(words))\n",
    "P_pos = defaultdict(lambda: defaultdict(Counter))\n",
    "for w in words:\n",
    "    for i, ch in enumerate(w):\n",
    "        P_pos[len(w)][i][ch] += 1\n",
    "P_pos = {L: {i: {c: n/sum(cnt.values()) for c, n in cnt.items()} \n",
    "             for i, cnt in pos.items()} for L, pos in P_pos.items()}\n",
    "P_next = defaultdict(Counter)\n",
    "for w in words:\n",
    "    for a, b in zip(w, w[1:]):\n",
    "        P_next[a][b] += 1\n",
    "P_next = {a: {b: n/sum(cnt.values()) for b, n in cnt.items()} \n",
    "          for a, cnt in P_next.items()}\n",
    "global_counts = Counter(\"\".join(words))\n",
    "total_letters = sum(global_counts.values())\n",
    "global_freq = {c: v/total_letters for c, v in global_counts.items()}\n",
    "\n",
    "def guess_next_letter(mask, guessed, words, P_pos, P_next, global_freq, alpha=1.0, beta=1.0, gamma=0.5):\n",
    "    regex = re.compile(\"^\" + mask.replace(\"_\", \".\") + \"$\")\n",
    "    candidates = [w for w in words if regex.match(w)]\n",
    "    scores = Counter()\n",
    "    if candidates:\n",
    "        L = len(mask)\n",
    "        for w in candidates:\n",
    "            for i, ch in enumerate(w):\n",
    "                if mask[i] != \"_\" or ch in guessed: continue\n",
    "                scores[ch] += alpha * P_pos.get(L, {}).get(i, {}).get(ch, 0)\n",
    "                scores[ch] += beta * (1/len(candidates))\n",
    "                if i > 0: scores[ch] += gamma * P_next.get(w[i-1], {}).get(ch, 0)\n",
    "                elif i < L-1: scores[ch] += gamma * P_next.get(ch, {}).get(w[i+1], 0)\n",
    "    if not scores:\n",
    "        for ch, p in global_freq.items():\n",
    "            if ch not in guessed: scores[ch] = p\n",
    "    return scores.most_common()\n",
    "\n",
    "def normalize_scores(scores):\n",
    "    total = sum(v for _, v in scores)\n",
    "    return [(ch, v/total) for ch, v in scores]\n",
    "\n",
    "mask, guessed = \"__pp_e\", {\"a\",\"e\",\"i\",\"o\",\"u\"}\n",
    "suggestions = guess_next_letter(mask, guessed, words, P_pos, P_next, global_freq)\n",
    "print(\"Top 10:\", suggestions[:10])\n",
    "print(\"Normalized:\", normalize_scores(suggestions)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3925c0f-4320-42f2-8c02-a4882540b803",
   "metadata": {},
   "source": [
    "The output ranks candidate letters for the word mask __pp_e (with vowels already guessed) by combining positional frequencies, bigram transitions, and global letter distributions. The scoring highlights ‘l’ as the most likely next letter (≈32% probability after normalization), followed by ‘c’ (≈21%) and ‘p’ (≈17%), with other letters receiving much smaller weights. This distribution reflects the model’s ability to balance positional likelihoods, local letter dependencies, and overall frequency trends when suggesting the most informative guesse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed642e5-3552-4a35-9622-785458291fc2",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c7ebf4-143c-49e5-bf2a-3ea813e2c3b1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7859a-7d3b-446c-8bd4-ff7dfa85fbad",
   "metadata": {},
   "source": [
    "# Trial Phase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a00a7d-0c8c-4766-9852-1efba5a98148",
   "metadata": {},
   "source": [
    "I experimented with multiple Hangman implementations, extending them iteratively by layering in approaches such as global letter frequency, positional probability distributions, bigram/substring continuation models, and entropy-based scoring rules to evaluate which strategy worked best. After testing these variations, I found the most effective method combined a regex-filtered candidate dictionary, substring-based n-gram lookups, and entropy-weighted frequency scoring (with fallback strategies when no strong candidate emerged). This final approach dynamically narrows the dictionary, scores letters using both frequency and entropy, and includes a vowel penalty when the vowel ratio of a word exceeds 0.51—leading to more balanced guesses and avoiding wasted attempts on unlikely high-vowel words.\n",
    "\n",
    "Our First Attempt is left at the end of this notebook. The result was:\n",
    "\n",
    "**Batch result: 28/40 wins (70.00% win rate)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeb8599-fe5e-42bb-9eb9-590a609cd001",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d3c7ec-216e-4ad2-9487-b8eaa2932cba",
   "metadata": {},
   "source": [
    "# Main Approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe61d3dd-42bd-4df8-8e06-3275dea58bb2",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6410230-9710-443a-90b6-b5558fa4292e",
   "metadata": {},
   "source": [
    "My final Hangman approach was shaped by exploratory data analysis on vowel ratios, frequency distributions, and conditional probabilities, which revealed useful heuristics such as penalizing overly vowel-heavy guesses (above a 0.51 ratio) and leveraging positional/bigram dependencies. Building on these findings, I implemented a layered strategy: filtering candidates with regex-matched dictionaries, scoring letters via entropy-weighted frequency counts, and backing off to substring-based n-gram lookups or global frequency distributions when uncertainty was high. This design balances statistical rigor with practical heuristics, allowing the model to dynamically adapt its guesses while avoiding systematic pitfalls uncovered during the EDA.\n",
    "\n",
    "The entropy used is **Shannon entropy**, defined as:  \n",
    "\n",
    "$$\n",
    "H(p) = - \\Big( p \\log_2(p) + (1 - p) \\log_2(1 - p) \\Big)\n",
    "$$\n",
    "\n",
    "\n",
    "From testing we have **Total Batch result: 80/110 wins (73% win rate)** Marking it as the top approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c382be3b-50ba-462b-a61b-e762439d6c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HangmanAPI(object):\n",
    "    def __init__(self, access_token=None, session=None, timeout=None):\n",
    "        self.hangman_url = self.determine_hangman_url()\n",
    "        self.access_token = access_token\n",
    "        self.session = session or requests.Session()\n",
    "        self.timeout = timeout\n",
    "        self.guessed_letters = []\n",
    "        full_dictionary_location = \"words_250000_train.txt\"\n",
    "        self.full_dictionary = self.build_dictionary(full_dictionary_location)        \n",
    "        self.full_dictionary_common_letter_sorted = collections.Counter(\"\".join(self.full_dictionary)).most_common()\n",
    "        self.current_dictionary = []\n",
    "\n",
    "    @staticmethod\n",
    "    def determine_hangman_url():\n",
    "        links = ['https://trexsim.com']\n",
    "        data = {link: 0 for link in links}\n",
    "        for link in links:\n",
    "\n",
    "            requests.get(link)\n",
    "\n",
    "            for i in range(10):\n",
    "                s = time.time()\n",
    "                requests.get(link)\n",
    "                data[link] = time.time() - s\n",
    "\n",
    "        link = sorted(data.items(), key=lambda x: x[1])[0][0]\n",
    "        link += '/trexsim/hangman'\n",
    "        return link\n",
    "\n",
    "    def guess(self, word):\n",
    "        vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "        def total_vowels(new_word):\n",
    "            return sum(1 for i in new_word if i in vowels) / len(new_word)\n",
    "    \n",
    "        def method_a(new_dictionary):\n",
    "            dictx = collections.Counter()\n",
    "            for words in new_dictionary:\n",
    "                temp = collections.Counter(words)\n",
    "                for i in temp:\n",
    "                    temp[i] = 1\n",
    "                dictx = dictx + temp\n",
    "            return dictx\n",
    "    \n",
    "        def method_b(n_word_dictionary, new_word):\n",
    "            new_dictionary = []\n",
    "            l = len(new_word)\n",
    "            for dict_word in n_word_dictionary.get(l, []):\n",
    "                if re.match(new_word, dict_word):\n",
    "                    new_dictionary.append(dict_word)\n",
    "            return new_dictionary\n",
    "    \n",
    "        def build_n_word_dictionary(df):\n",
    "            max_length = max(len(w) for w in df)\n",
    "            n_word_dictionary = {i: [] for i in range(3, 30)}\n",
    "            count = 3\n",
    "            while count <= max_length:\n",
    "                for words in df:\n",
    "                    if len(words) >= count:\n",
    "                        for i in range(len(words) - count + 1):\n",
    "                            n_word_dictionary[count].append(words[i:i+count])\n",
    "                count += 1\n",
    "            return n_word_dictionary\n",
    "    \n",
    "        def score_entropy(counter, total_words):\n",
    "            best_letter, best_score = None, -1\n",
    "            for letter, count in counter.items():\n",
    "                if letter in self.guessed_letters:\n",
    "                    continue\n",
    "                p = count / total_words\n",
    "                score_base = count\n",
    "                score_entropy = - (p * math.log2(p + 1e-12) + (1-p) * math.log2(1-p + 1e-12))\n",
    "                score = score_base + 0.3 * score_entropy\n",
    "                if score > best_score:\n",
    "                    best_letter, best_score = letter, score\n",
    "            return best_letter, best_score\n",
    "    \n",
    "        n_word_dictionary = build_n_word_dictionary(self.full_dictionary)\n",
    "        edit_word = word[::2].replace(\"_\", \".\")\n",
    "        len_word = len(edit_word)\n",
    "        current_dictionary = self.current_dictionary\n",
    "    \n",
    "        new_dictionary = []\n",
    "        for dict_word in current_dictionary:\n",
    "            if len(dict_word) != len_word:\n",
    "                continue\n",
    "            if re.match(edit_word, dict_word):\n",
    "                new_dictionary.append(dict_word)\n",
    "        self.current_dictionary = new_dictionary\n",
    "    \n",
    "        c = method_a(new_dictionary)\n",
    "        guess_letter, _ = score_entropy(c, sum(c.values()))\n",
    "    \n",
    "        if guess_letter is None:\n",
    "            new_dictionary = method_b(n_word_dictionary, edit_word)\n",
    "            c = method_a(new_dictionary)\n",
    "            guess_letter, _ = score_entropy(c, sum(c.values()))\n",
    "    \n",
    "        if guess_letter is None:\n",
    "            x = int(len(edit_word) / 2)\n",
    "            if x >= 3:\n",
    "                c = collections.Counter()\n",
    "                for i in range(len(edit_word) - x + 1):\n",
    "                    s = edit_word[i:i + x]\n",
    "                    new_dictionary = method_b(n_word_dictionary, s)\n",
    "                    temp = method_a(new_dictionary)\n",
    "                    c = c + temp\n",
    "                guess_letter, _ = score_entropy(c, sum(c.values()))\n",
    "    \n",
    "        if guess_letter is None:\n",
    "            x = int(len(edit_word) / 3)\n",
    "            if x >= 3:\n",
    "                c = collections.Counter()\n",
    "                for i in range(len(edit_word) - x + 1):\n",
    "                    s = edit_word[i:i + x]\n",
    "                    new_dictionary = method_b(n_word_dictionary, s)\n",
    "                    temp = method_a(new_dictionary)\n",
    "                    c = c + temp\n",
    "                guess_letter, _ = score_entropy(c, sum(c.values()))\n",
    "    \n",
    "        if guess_letter is None:\n",
    "            c = collections.Counter(dict(self.full_dictionary_common_letter_sorted))\n",
    "            guess_letter, _ = score_entropy(c, sum(c.values()))\n",
    "    \n",
    "        if guess_letter in vowels and total_vowels(edit_word) > 0.51: #EDA Value\n",
    "            self.guessed_letters.append(guess_letter)\n",
    "            guess_letter = None\n",
    "            for letter, _ in c.most_common():\n",
    "                if letter not in self.guessed_letters and letter not in vowels:\n",
    "                    guess_letter = letter\n",
    "                    break\n",
    "    \n",
    "        return guess_letter\n",
    "\n",
    "\n",
    "    ##########################################################\n",
    "    # You'll likely not need to modify any of the code below #\n",
    "    ##########################################################\n",
    "    \n",
    "    def build_dictionary(self, dictionary_file_location):\n",
    "        text_file = open(dictionary_file_location,\"r\")\n",
    "        full_dictionary = text_file.read().splitlines()\n",
    "        text_file.close()\n",
    "        return full_dictionary\n",
    "                \n",
    "    def start_game(self, practice=True, verbose=True):\n",
    "        # reset guessed letters to empty set and current plausible dictionary to the full dictionary\n",
    "        self.guessed_letters = []\n",
    "        self.current_dictionary = self.full_dictionary\n",
    "                         \n",
    "        response = self.request(\"/new_game\", {\"practice\":practice})\n",
    "        if response.get('status')==\"approved\":\n",
    "            game_id = response.get('game_id')\n",
    "            word = response.get('word')\n",
    "            tries_remains = response.get('tries_remains')\n",
    "            if verbose:\n",
    "                print(\"Successfully start a new game! Game ID: {0}. # of tries remaining: {1}. Word: {2}.\".format(game_id, tries_remains, word))\n",
    "            while tries_remains>0:\n",
    "                # get guessed letter from user code\n",
    "                guess_letter = self.guess(word)\n",
    "                    \n",
    "                # append guessed letter to guessed letters field in hangman object\n",
    "                self.guessed_letters.append(guess_letter)\n",
    "                if verbose:\n",
    "                    print(\"Guessing letter: {0}\".format(guess_letter))\n",
    "                    \n",
    "                try:    \n",
    "                    res = self.request(\"/guess_letter\", {\"request\":\"guess_letter\", \"game_id\":game_id, \"letter\":guess_letter})\n",
    "                except HangmanAPIError:\n",
    "                    print('HangmanAPIError exception caught on request.')\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print('Other exception caught on request.')\n",
    "                    raise e\n",
    "               \n",
    "                if verbose:\n",
    "                    print(\"Sever response: {0}\".format(res))\n",
    "                status = res.get('status')\n",
    "                tries_remains = res.get('tries_remains')\n",
    "                if status==\"success\":\n",
    "                    if verbose:\n",
    "                        print(\"Successfully finished game: {0}\".format(game_id))\n",
    "                    return True\n",
    "                elif status==\"failed\":\n",
    "                    reason = res.get('reason', '# of tries exceeded!')\n",
    "                    if verbose:\n",
    "                        print(\"Failed game: {0}. Because of: {1}\".format(game_id, reason))\n",
    "                    return False\n",
    "                elif status==\"ongoing\":\n",
    "                    word = res.get('word')\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"Failed to start a new game\")\n",
    "        return status==\"success\"\n",
    "        \n",
    "    def my_status(self):\n",
    "        return self.request(\"/my_status\", {})\n",
    "        \n",
    "    def request(\n",
    "            self, path, args=None, post_args=None, method=None):\n",
    "        if args is None:\n",
    "            args = dict()\n",
    "        if post_args is not None:\n",
    "            method = \"POST\"\n",
    "\n",
    "        if self.access_token:\n",
    "            if post_args and \"access_token\" not in post_args:\n",
    "                post_args[\"access_token\"] = self.access_token\n",
    "            elif \"access_token\" not in args:\n",
    "                args[\"access_token\"] = self.access_token\n",
    "\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        num_retry, time_sleep = 50, 2\n",
    "        for it in range(num_retry):\n",
    "            try:\n",
    "                response = self.session.request(\n",
    "                    method or \"GET\",\n",
    "                    self.hangman_url + path,\n",
    "                    timeout=self.timeout,\n",
    "                    params=args,\n",
    "                    data=post_args,\n",
    "                    verify=False\n",
    "                )\n",
    "                break\n",
    "            except requests.HTTPError as e:\n",
    "                response = json.loads(e.read())\n",
    "                raise HangmanAPIError(response)\n",
    "            except requests.exceptions.SSLError as e:\n",
    "                if it + 1 == num_retry:\n",
    "                    raise\n",
    "                time.sleep(time_sleep)\n",
    "\n",
    "        headers = response.headers\n",
    "        if 'json' in headers['content-type']:\n",
    "            result = response.json()\n",
    "        elif \"access_token\" in parse_qs(response.text):\n",
    "            query_str = parse_qs(response.text)\n",
    "            if \"access_token\" in query_str:\n",
    "                result = {\"access_token\": query_str[\"access_token\"][0]}\n",
    "                if \"expires\" in query_str:\n",
    "                    result[\"expires\"] = query_str[\"expires\"][0]\n",
    "            else:\n",
    "                raise HangmanAPIError(response.json())\n",
    "        else:\n",
    "            raise HangmanAPIError('Maintype was not text, or querystring')\n",
    "\n",
    "        if result and isinstance(result, dict) and result.get(\"error\"):\n",
    "            raise HangmanAPIError(result)\n",
    "        return result\n",
    "    \n",
    "class HangmanAPIError(Exception):\n",
    "    def __init__(self, result):\n",
    "        self.result = result\n",
    "        self.code = None\n",
    "        try:\n",
    "            self.type = result[\"error_code\"]\n",
    "        except (KeyError, TypeError):\n",
    "            self.type = \"\"\n",
    "\n",
    "        try:\n",
    "            self.message = result[\"error_description\"]\n",
    "        except (KeyError, TypeError):\n",
    "            try:\n",
    "                self.message = result[\"error\"][\"message\"]\n",
    "                self.code = result[\"error\"].get(\"code\")\n",
    "                if not self.type:\n",
    "                    self.type = result[\"error\"].get(\"type\", \"\")\n",
    "            except (KeyError, TypeError):\n",
    "                try:\n",
    "                    self.message = result[\"error_msg\"]\n",
    "                except (KeyError, TypeError):\n",
    "                    self.message = result\n",
    "\n",
    "        Exception.__init__(self, self.message) \n",
    "\n",
    "api = HangmanAPI(access_token=\"87c3dbc9aba55cea61dbae2f9ba238\", timeout=2000)\n",
    "wins = 0\n",
    "losses = 0\n",
    "runs = 50   \n",
    "for i in range(runs):\n",
    "    success = api.start_game(practice=1, verbose=1) \n",
    "    if success:\n",
    "        wins += 1\n",
    "        print(f\"Game {i+1}: WIN\")\n",
    "    else:\n",
    "        losses += 1\n",
    "        print(f\"Game {i+1}: LOSS\")\n",
    "print(f\"Batch result: {wins}/{runs} wins ({wins/runs:.2%} win rate)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e08153f-f991-41b2-b0a7-9f654d2f2ac6",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca474fd-0c08-4831-a2ff-0c18b8deabfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd42a4bc-6dc2-41d4-b303-f264ea7f5ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a7f1e8-5612-4e62-b4be-b758275439be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dc35ff-c580-4b53-81d1-f39fafd66a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8cd2d0-b616-4226-96ae-3db2e7672dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f653d9-5b30-4bcc-a1c7-13166488002f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "775b1cba-d691-43dc-870f-c698ba5a67b0",
   "metadata": {},
   "source": [
    "## Playing recorded games:\n",
    "Please finalize your code prior to running the cell below. Once this code executes once successfully your submission will be finalized. Our system will not allow you to rerun any additional games.\n",
    "\n",
    "Please note that it is expected that after you successfully run this block of code that subsequent runs will result in the error message \"Your account has been deactivated\".\n",
    "\n",
    "Once you've run this section of the code your submission is complete. Please send us your source code via email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74190e48-5c21-4e4f-9743-3e9925cb8362",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    print('Playing ', i, ' th game')\n",
    "    # Uncomment the following line to execute your final runs. Do not do this until you are satisfied with your submission\n",
    "    api.start_game(practice=0,verbose=False)\n",
    "    \n",
    "    # DO NOT REMOVE as otherwise the server may lock you out for too high frequency of requests\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1546d6-a1ae-4101-a7b8-79f25a250ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b4de2c0-476a-4d43-b00f-bad72a7f3bf1",
   "metadata": {},
   "source": [
    "## To check your game statistics\n",
    "1. Simply use \"my_status\" method.\n",
    "2. Returns your total number of games, and number of wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74990904-f1c3-4c2a-bf09-bd834fc8213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[total_practice_runs,total_recorded_runs,total_recorded_successes,total_practice_successes] = api.my_status() # Get my game stats: (# of tries, # of wins)\n",
    "success_rate = total_recorded_successes/total_recorded_runs\n",
    "print('overall success rate = %.3f' % success_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fd792c-494d-42b6-9c12-c0aebc67fc78",
   "metadata": {},
   "source": [
    "The solver achieved a 0.73 success rate on the training set but only 0.527 on the final test set, underscoring overfitting to the training dictionary. Since the test set excluded words from the provided dictionary, strategies that relied on word elimination were less effective. More general rules, such as leveraging positional letter frequencies, vowel–consonant ratios, bigram and suffix patterns, or entropy-based exploration, would likely generalise better, as they capture broader orthographic regularities rather than memorized word lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bd73f3-67ec-44e9-bfe9-ec7104dec7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea640ccd-a2c5-4159-8b0e-a26c95938729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "159323d3-9f46-47c5-b85d-22755be21627",
   "metadata": {},
   "source": [
    "## Initial Method.\n",
    "\n",
    "Simplifying  the approach lowered the computational cost significantly and slightly inceased the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec375b34-5b3a-411d-9a84-84f30103db1e",
   "metadata": {},
   "source": [
    "This implementation of the Hangman solver is a feature-rich system that combines multiple probabilistic and heuristic methods, such as global letter frequency, positional distributions, n-gram matches, bigram continuations, and suffix/prefix heuristics, to select the most informative next guess. It also incorporates smoothing techniques like entropy-based scoring and a fallback mechanism when other strategies fail. While it originally experimented with more complex adjustments (e.g., vowel penalties based on ratio thresholds), in practice a simpler focus on vowel handling proved more effective and consistent. For this reason, we leave the solver in its current state, noting that future refinements may benefit more from streamlined heuristics than added layers of complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c580991-48a7-4d61-8a1c-adb9b1a4143c",
   "metadata": {},
   "source": [
    "Current Accuracy 67.5% With Shannon Entropy:\n",
    "\n",
    "**Batch result: 27/40 wins (67.50% win rate)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554eda31-ef9e-4da1-8ff1-bfe3bdecea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HangmanAPI(object):\n",
    "    def __init__(self, access_token=None, session=None, timeout=None):\n",
    "        self.hangman_url = self.determine_hangman_url()\n",
    "        self.access_token = access_token\n",
    "        self.session = session or requests.Session()\n",
    "        self.timeout = timeout\n",
    "        self.guessed_letters = []\n",
    "        full_dictionary_location = \"words_250000_train.txt\"\n",
    "        self.full_dictionary = self.build_dictionary(full_dictionary_location)\n",
    "        self.full_dictionary_common_letter_sorted = collections.Counter(\n",
    "            \"\".join(self.full_dictionary)\n",
    "        ).most_common()\n",
    "        self.current_dictionary = []\n",
    "        self.alphabet = sorted(set(\"\".join(self.full_dictionary)))\n",
    "        self.P_next = {a: collections.Counter() for a in self.alphabet}\n",
    "        self.len_freq = collections.Counter(len(w) for w in self.full_dictionary)\n",
    "        self.global_letter_freq = collections.Counter(\"\".join(self.full_dictionary))\n",
    "        for w in self.full_dictionary:\n",
    "            for a, b in zip(w, w[1:]):\n",
    "                self.P_next[a][b] += 1\n",
    "        for a in self.P_next:\n",
    "            total = sum(self.P_next[a].values())\n",
    "            if total > 0:\n",
    "                for b in self.P_next[a]:\n",
    "                    self.P_next[a][b] /= total\n",
    "        self.P_pos = {}  # P_pos[length][position][letter]\n",
    "        for w in self.full_dictionary:\n",
    "            L = len(w)\n",
    "            if L not in self.P_pos:\n",
    "                self.P_pos[L] = {}\n",
    "            for i, ch in enumerate(w):\n",
    "                if i not in self.P_pos[L]:\n",
    "                    self.P_pos[L][i] = collections.Counter()\n",
    "                self.P_pos[L][i][ch] += 1\n",
    "        for L in self.P_pos:\n",
    "            for i in self.P_pos[L]:\n",
    "                total = sum(self.P_pos[L][i].values())\n",
    "                for ch in self.P_pos[L][i]:\n",
    "                    self.P_pos[L][i][ch] /= total\n",
    "        self.P_len = {}  # P_len[length][letter]\n",
    "        for w in self.full_dictionary:\n",
    "            L = len(w)\n",
    "            if L not in self.P_len:\n",
    "                self.P_len[L] = collections.Counter()\n",
    "            self.P_len[L].update(w)  # count letters in words of this length\n",
    "        for L in self.P_len:\n",
    "            total = sum(self.P_len[L].values())\n",
    "            for ch in self.P_len[L]:\n",
    "                self.P_len[L][ch] /= total\n",
    "        self.n_word_dictionary = self.build_n_word_dictionary(self.full_dictionary)\n",
    "\n",
    "\n",
    "    def build_n_word_dictionary(self, df):\n",
    "        max_length = max(len(w) for w in df)\n",
    "        n_word_dictionary = {i: [] for i in range(3, 30)}  # store substrings length 3–29\n",
    "        for count in range(3, min(max_length, 30) + 1):\n",
    "            for word in df:\n",
    "                if len(word) >= count:\n",
    "                    for i in range(len(word) - count + 1):\n",
    "                        n_word_dictionary[count].append(word[i:i+count])\n",
    "        return n_word_dictionary\n",
    "\n",
    "    @staticmethod\n",
    "    def determine_hangman_url():\n",
    "        links = ['https://trexsim.com']\n",
    "        data = {link: 0 for link in links}\n",
    "        for link in links:\n",
    "            requests.get(link)\n",
    "            for i in range(10):\n",
    "                s = time.time()\n",
    "                requests.get(link)\n",
    "                data[link] = time.time() - s\n",
    "        link = sorted(data.items(), key=lambda x: x[1])[0][0]\n",
    "        link += '/trexsim/hangman'\n",
    "        return link\n",
    "\n",
    "    def apply_vowel_penalty(self, candidates, new_word):\n",
    "        vowel_ratio = sum(ch in vowels for ch in new_word if ch != \".\") / max(1, len(new_word))\n",
    "        if vowel_ratio > 0.55:\n",
    "            for v in vowels:\n",
    "                if v in candidates:\n",
    "                    candidates[v] *= 0.3\n",
    "        return candidates\n",
    "\n",
    "    def global_fallback(self, new_word):\n",
    "        candidates = collections.Counter()\n",
    "        L = len(new_word)\n",
    "        length_weight = self.len_freq[L] / sum(self.len_freq.values())\n",
    "        for i, ch in enumerate(new_word):\n",
    "            if ch != \".\":\n",
    "                continue\n",
    "            if i > 0 and new_word[i-1] != \".\":\n",
    "                left = new_word[i-1]\n",
    "                for nxt, p in self.P_next.get(left, {}).items():\n",
    "                    if nxt not in self.guessed_letters:\n",
    "                        candidates[nxt] += p * 2.0\n",
    "            if i < len(new_word)-1 and new_word[i+1] != \".\":\n",
    "                right = new_word[i+1]\n",
    "                for prev, p in self.P_next.items():\n",
    "                    if right in p:\n",
    "                        prob = p[right]\n",
    "                        if prev not in self.guessed_letters:\n",
    "                            candidates[prev] += prob * 1.5\n",
    "        for ltr, count in self.global_letter_freq.items():\n",
    "            if ltr not in self.guessed_letters:\n",
    "                candidates[ltr] += count / sum(self.global_letter_freq.values()) * length_weight\n",
    "        if not candidates:\n",
    "            return None\n",
    "        candidates = self.apply_vowel_penalty(candidates, new_word)\n",
    "        return candidates.most_common(1)[0][0]\n",
    "    \n",
    "    def guess(self, word):    \n",
    "        def method_update(new_dictionary):\n",
    "            dictx = collections.Counter()\n",
    "            for words in new_dictionary:\n",
    "                dictx.update(set(words)) \n",
    "            return dictx\n",
    "    \n",
    "        def method_regex(n_word_dictionary, new_word):\n",
    "            pattern = re.compile(new_word)\n",
    "            return [w for w in n_word_dictionary.get(len(new_word), []) if pattern.match(w)]\n",
    "\n",
    "        # Shannon Entropy\n",
    "        def score_distribution(counter, total_words):\n",
    "            best_letter, best_score = None, -1\n",
    "            for letter in counter:\n",
    "                if letter in self.guessed_letters:\n",
    "                    continue\n",
    "                p = counter[letter] / total_words\n",
    "                if p == 0 or p == 1:\n",
    "                    score = 0\n",
    "                else:\n",
    "                    score = -p * math.log2(p) - (1-p) * math.log2(1-p)\n",
    "                if score > best_score:\n",
    "                    best_letter, best_score = letter, score\n",
    "            return best_letter, best_score\n",
    "\n",
    "    \n",
    "        #  MAIN \n",
    "        new_word = word[::2].replace(\"_\", \".\")\n",
    "        len_word = len(new_word)\n",
    "        method_candidates = []\n",
    "    \n",
    "        # Method 1: current dictionary \n",
    "        new_dictionary = [\n",
    "            dw for dw in self.current_dictionary\n",
    "            if len(dw) == len_word and re.match(new_word, dw)\n",
    "        ]\n",
    "        self.current_dictionary = new_dictionary\n",
    "        if new_dictionary:\n",
    "            c = method_update(new_dictionary)\n",
    "            best, score = score_distribution(c, len(new_dictionary))\n",
    "            if best:\n",
    "                method_candidates.append((\"Method 1 (current dictionary)\", best, score))\n",
    "    \n",
    "        # Method 2: n-gram dictionary full match\n",
    "        new_dictionary = method_regex(self.n_word_dictionary, new_word)\n",
    "        if new_dictionary:\n",
    "            c = method_update(new_dictionary)\n",
    "            best, score = score_distribution(c, len(new_dictionary))\n",
    "            if best:\n",
    "                method_candidates.append((\"Method 2 (n-gram full)\", best, score))\n",
    "\n",
    "\n",
    "        #  Method 3: half substrings \n",
    "        x = int(len(new_word) / 2)\n",
    "        if x >= 3:\n",
    "            c = collections.Counter()\n",
    "            for i in range(len(new_word) - x + 1):\n",
    "                s = new_word[i:i + x]\n",
    "                new_dictionary = method_regex(self.n_word_dictionary, s)\n",
    "                c.update(method_update(new_dictionary))\n",
    "            if c:\n",
    "                best, score = score_distribution(c, sum(c.values()))\n",
    "                if best:\n",
    "                    method_candidates.append((\"Method 3 (half substrings)\", best, score))\n",
    "    \n",
    "        #  Method 4: third substrings \n",
    "        x = int(len(new_word) / 3)\n",
    "        if x >= 3:\n",
    "            c = collections.Counter()\n",
    "            for i in range(len(new_word) - x + 1):\n",
    "                s = new_word[i:i + x]\n",
    "                new_dictionary = method_regex(self.n_word_dictionary, s)\n",
    "                c.update(method_update(new_dictionary))\n",
    "            if c:\n",
    "                best, score = score_distribution(c, sum(c.values()))\n",
    "                if best:\n",
    "                    method_candidates.append((\"Method 4 (third substrings)\", best, score))\n",
    "    \n",
    "        # Method 5: global frequency \n",
    "        c = collections.Counter(dict(self.full_dictionary_common_letter_sorted))\n",
    "        best, score = score_distribution(c, sum(c.values()))\n",
    "        if best:\n",
    "            method_candidates.append((\"Method 5 (global frequency)\", best, score))\n",
    "    \n",
    "        #  Method 6: positional frequency\n",
    "        c = collections.Counter()\n",
    "        for i, ch in enumerate(new_word):\n",
    "            if ch != \".\":\n",
    "                continue\n",
    "            for letter, prob in self.P_pos.get(len_word, {}).get(i, {}).items():\n",
    "                if letter not in self.guessed_letters:\n",
    "                    c[letter] += prob\n",
    "        if c:\n",
    "            best, score = score_distribution(c, sum(c.values()))\n",
    "            if best:\n",
    "                method_candidates.append((\"Method 6 (positional frequency)\", best, score))\n",
    "\n",
    "        # --- Method 7: length-conditioned frequency ---\n",
    "        c = collections.Counter()\n",
    "        for letter, prob in self.P_len.get(len_word, {}).items():\n",
    "            if letter not in self.guessed_letters:\n",
    "                c[letter] += prob\n",
    "        if c:\n",
    "            best, score = score_distribution(c, sum(c.values()))\n",
    "            if best:\n",
    "                method_candidates.append((\"Method 7 (length-conditioned frequency)\", best, score))\n",
    "\n",
    "        # Method 8: bigram continuation\n",
    "        c = collections.Counter()\n",
    "        for i, ch in enumerate(new_word):\n",
    "            if ch != \".\":\n",
    "                continue\n",
    "            if i > 0 and new_word[i-1] != \".\":\n",
    "                left = new_word[i-1]\n",
    "                for nxt, prob in self.P_next.get(left, {}).items():\n",
    "                    if nxt not in self.guessed_letters:\n",
    "                        c[nxt] += prob\n",
    "            if i < len(new_word)-1 and new_word[i+1] != \".\":\n",
    "                right = new_word[i+1]\n",
    "                for prev, prob_dict in self.P_next.items():\n",
    "                    if right in prob_dict:\n",
    "                        if prev not in self.guessed_letters:\n",
    "                            c[prev] += prob_dict[right]\n",
    "        if c:\n",
    "            best, score = score_distribution(c, sum(c.values()))\n",
    "            if best:\n",
    "                method_candidates.append((\"Method 8 (bigram continuation)\", best, score))\n",
    "    \n",
    "        # Method 9: suffix/prefix heuristics\n",
    "        c = collections.Counter()\n",
    "        suffixes = ['ing', 'ed', 'ly', 'tion']\n",
    "        prefixes = ['re', 'un', 'co']\n",
    "        for suf in suffixes:\n",
    "            if new_word.endswith('.' * len(suf)):\n",
    "                for letter in suf:\n",
    "                    if letter not in self.guessed_letters:\n",
    "                        c[letter] += 1.0  # simple weighting\n",
    "        for pre in prefixes:\n",
    "            if new_word.startswith('.' * len(pre)):\n",
    "                for letter in pre:\n",
    "                    if letter not in self.guessed_letters:\n",
    "                        c[letter] += 1.0\n",
    "        if c:\n",
    "            best, score = score_distribution(c, sum(c.values()))\n",
    "            if best:\n",
    "                method_candidates.append((\"Method 9 (suffix/prefix heuristics)\", best, score))      \n",
    "\n",
    "    \n",
    "        # Pick best\n",
    "        if method_candidates:\n",
    "            method, guess_letter, score = max(method_candidates, key=lambda x: x[2])\n",
    "            self.guessed_letters.append(guess_letter)\n",
    "            print(f\"[DEBUG] {method} chose: {guess_letter} (score={score:.4f})\")\n",
    "        else:\n",
    "            # --- Fallback ---\n",
    "            guess_letter = self.global_fallback(new_word) or random.choice(self.alphabet)\n",
    "            self.guessed_letters.append(guess_letter)\n",
    "            print(f\"[DEBUG] Fallback chose: {guess_letter}\")\n",
    "    \n",
    "        return guess_letter\n",
    "\n",
    "    \n",
    "\n",
    "    def build_dictionary(self, dictionary_file_location):\n",
    "        text_file = open(dictionary_file_location,\"r\")\n",
    "        full_dictionary = text_file.read().splitlines()\n",
    "        text_file.close()\n",
    "        return full_dictionary\n",
    "                \n",
    "    def start_game(self, practice=True, verbose=True):\n",
    "        self.guessed_letters = []\n",
    "        self.current_dictionary = self.full_dictionary\n",
    "        response = self.request(\"/new_game\", {\"practice\":practice})\n",
    "        if response.get('status')==\"approved\":\n",
    "            game_id = response.get('game_id')\n",
    "            word = response.get('word')\n",
    "            tries_remains = response.get('tries_remains')\n",
    "            if verbose:\n",
    "                print(\"Successfully start a new game! Game ID: {0}. # of tries remaining: {1}. Word: {2}.\".format(game_id, tries_remains, word))\n",
    "            while tries_remains>0:\n",
    "                guess_letter = self.guess(word)\n",
    "                self.guessed_letters.append(guess_letter)\n",
    "                if verbose:\n",
    "                    print(\"Guessing letter: {0}\".format(guess_letter))\n",
    "                try:    \n",
    "                    res = self.request(\"/guess_letter\", {\"request\":\"guess_letter\", \"game_id\":game_id, \"letter\":guess_letter})\n",
    "                except HangmanAPIError:\n",
    "                    print('HangmanAPIError exception caught on request.')\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print('Other exception caught on request.')\n",
    "                    raise e\n",
    "                if verbose:\n",
    "                    print(\"Sever response: {0}\".format(res))\n",
    "                status = res.get('status')\n",
    "                tries_remains = res.get('tries_remains')\n",
    "                if status==\"success\":\n",
    "                    if verbose:\n",
    "                        print(\"Successfully finished game: {0}\".format(game_id))\n",
    "                    return True\n",
    "                elif status==\"failed\":\n",
    "                    reason = res.get('reason', '# of tries exceeded!')\n",
    "                    if verbose:\n",
    "                        print(\"Failed game: {0}. Because of: {1}\".format(game_id, reason))\n",
    "                    return False\n",
    "                elif status==\"ongoing\":\n",
    "                    word = res.get('word')\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"Failed to start a new game\")\n",
    "        return status==\"success\"\n",
    "        \n",
    "    def my_status(self):\n",
    "        return self.request(\"/my_status\", {})\n",
    "\n",
    "        \n",
    "    def request(\n",
    "            self, path, args=None, post_args=None, method=None):\n",
    "        if args is None:\n",
    "            args = dict()\n",
    "        if post_args is not None:\n",
    "            method = \"POST\"\n",
    "\n",
    "        if self.access_token:\n",
    "            if post_args and \"access_token\" not in post_args:\n",
    "                post_args[\"access_token\"] = self.access_token\n",
    "            elif \"access_token\" not in args:\n",
    "                args[\"access_token\"] = self.access_token\n",
    "\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        num_retry, time_sleep = 50, 2\n",
    "        for it in range(num_retry):\n",
    "            try:\n",
    "                response = self.session.request(\n",
    "                    method or \"GET\",\n",
    "                    self.hangman_url + path,\n",
    "                    timeout=self.timeout,\n",
    "                    params=args,\n",
    "                    data=post_args,\n",
    "                    verify=False\n",
    "                )\n",
    "                break\n",
    "            except requests.HTTPError as e:\n",
    "                response = json.loads(e.read())\n",
    "                raise HangmanAPIError(response)\n",
    "            except requests.exceptions.SSLError as e:\n",
    "                if it + 1 == num_retry:\n",
    "                    raise\n",
    "                time.sleep(time_sleep)\n",
    "\n",
    "        headers = response.headers\n",
    "        if 'json' in headers['content-type']:\n",
    "            result = response.json()\n",
    "        elif \"access_token\" in parse_qs(response.text):\n",
    "            query_str = parse_qs(response.text)\n",
    "            if \"access_token\" in query_str:\n",
    "                result = {\"access_token\": query_str[\"access_token\"][0]}\n",
    "                if \"expires\" in query_str:\n",
    "                    result[\"expires\"] = query_str[\"expires\"][0]\n",
    "            else:\n",
    "                raise HangmanAPIError(response.json())\n",
    "        else:\n",
    "            raise HangmanAPIError('Maintype was not text, or querystring')\n",
    "\n",
    "        if result and isinstance(result, dict) and result.get(\"error\"):\n",
    "            raise HangmanAPIError(result)\n",
    "        return result\n",
    "    \n",
    "class HangmanAPIError(Exception):\n",
    "    def __init__(self, result):\n",
    "        self.result = result\n",
    "        self.code = None\n",
    "        try:\n",
    "            self.type = result[\"error_code\"]\n",
    "        except (KeyError, TypeError):\n",
    "            self.type = \"\"\n",
    "\n",
    "        try:\n",
    "            self.message = result[\"error_description\"]\n",
    "        except (KeyError, TypeError):\n",
    "            try:\n",
    "                self.message = result[\"error\"][\"message\"]\n",
    "                self.code = result[\"error\"].get(\"code\")\n",
    "                if not self.type:\n",
    "                    self.type = result[\"error\"].get(\"type\", \"\")\n",
    "            except (KeyError, TypeError):\n",
    "                try:\n",
    "                    self.message = result[\"error_msg\"]\n",
    "                except (KeyError, TypeError):\n",
    "                    self.message = result\n",
    "\n",
    "        Exception.__init__(self, self.message) \n",
    "\n",
    "api = HangmanAPI(access_token=\"87c3dbc9aba55cea61dbae2f9ba238\", timeout=2000)\n",
    "wins = 0\n",
    "losses = 0\n",
    "runs = 5 \n",
    "\n",
    "for i in range(runs):\n",
    "    success = api.start_game(practice=1, verbose=1)  # or practice=0 for official\n",
    "    if success:\n",
    "        wins += 1\n",
    "        print(f\"Game {i+1}: WIN\")\n",
    "    else:\n",
    "        losses += 1\n",
    "        print(f\"Game {i+1}: LOSS\")\n",
    "\n",
    "print(f\"Batch result: {wins}/{runs} wins ({wins/runs:.2%} win rate)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db17d9c-b687-4f68-8143-46ffb4bb52b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
